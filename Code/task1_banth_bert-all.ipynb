{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7a63a7f-1ae8-4f9d-8d7d-b3c7339a0124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from torch.optim import AdamW  # <-- use this instead\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as tq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "MODEL_NAME =\"csebuetnlp/banglabert\"\n",
    "\n",
    "# You can keep these as they are or tune them\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0157876-41f3-4d68-969d-f492cb3cbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "182ddff0-5638-4dfa-8288-5dad145ac823",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'blp25_hatespeech_subtask_1A_train.tsv'\n",
    "validation_file = 'blp25_hatespeech_subtask_1A_dev.tsv'\n",
    "test_file = 'blp25_hatespeech_subtask_1A_test.tsv'\n",
    "\n",
    "\n",
    "validation_file2 = 'blp25_hatespeech_subtask_1A_dev_test_with_labels.tsv'\n",
    "\n",
    "test_file = 'blp25_hatespeech_subtask_1A_test_with_labels.tsv'\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "# Load train/val/test DataFrames\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "# Load train/val/test DataFrames\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "# Load train/val/test DataFrames\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\")\n",
    "dev_df1 = pd.read_csv(validation_file , sep=\"\\t\")\n",
    "dev_df2 = pd.read_csv(validation_file2 , sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\")\n",
    "\n",
    "\n",
    "\n",
    "# Concatenate them into one dataframe\n",
    "train_df = pd.concat([train_df, dev_df1, dev_df2], ignore_index=True)\n",
    "dev_df =test_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddc20aa3-ad03-4b4f-8771-529634b73245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147963</td>\n",
       "      <td>‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¨‡¶∞‡ßç‡¶°‡¶æ‡¶∞ ‡¶ó‡¶æ‡¶∞‡ßç‡¶° ‡¶¶‡ßá‡¶∞‡¶ï‡ßá ‡¶è‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡¶æ‡¶π‡¶æ‡¶∞‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶π...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214275</td>\n",
       "      <td>‡¶õ‡ßã‡¶ü‡¶¨‡ßá‡¶≤‡¶æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßá‡¶ï ‡¶ï‡¶∑‡ßç‡¶ü ‡¶ï‡¶∞‡ßá ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ó‡¶æ‡¶≤‡¶æ‡¶ó‡¶æ‡¶≤‡¶ø ‡¶∂‡¶ø‡¶ñ‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849172</td>\n",
       "      <td>‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶è ‡¶®‡¶ø‡¶ú‡ßá‡¶ï‡ßá ‡¶¨‡¶æ‡¶¶‡ßÅ‡¶∞ ‡¶¨‡¶æ‡¶®‡¶æ‡¶á‡ßü‡¶æ ‡¶´‡ßá‡¶≤‡¶õ‡ßá‡¶® ‡¶∞‡ßá</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>821985</td>\n",
       "      <td>‡¶ö‡¶ø‡¶® ‡¶≠‡¶æ‡¶∞‡¶§ ‡¶∞‡¶æ‡¶∂‡¶ø‡ßü‡¶æ ‡¶è‡¶á ‡¶§‡¶ø‡¶® ‡¶¶‡ßá‡¶∂ ‡¶è‡¶ï ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶ï‡ßá ‡¶∂‡¶æ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477288</td>\n",
       "      <td>‡¶è‡¶ü‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶ï‡ßá ‡¶ï‡¶∞‡¶¨‡ßá‡¶Ø‡ßá ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá ‡¶∏‡ßá‡¶á ‡¶§‡ßã ‡¶π‡¶≤‡ßã ‡¶è‡¶á ...</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40541</th>\n",
       "      <td>776466</td>\n",
       "      <td>‡¶∏‡¶§‡ßç‡¶Ø ‡¶ï‡¶•‡¶æ ‡¶§‡ßá‡¶§‡ßÅ ‡¶≤‡¶æ‡¶ó‡ßá</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40542</th>\n",
       "      <td>849227</td>\n",
       "      <td>‡¶è‡¶á ‡¶´‡¶ï‡¶ø‡¶®‡¶®‡¶ø ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ü‡¶æ ‡¶Ü‡¶∞ ‡¶ï‡¶§ ‡¶®‡¶æ‡¶ü‡¶ï ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40543</th>\n",
       "      <td>532697</td>\n",
       "      <td>‡¶¶‡ßá‡¶ñ‡ßã ‡¶Ü‡¶ú‡¶ï‡ßá ‡¶ï‡¶æ‡¶∞ ‡¶´‡¶ø‡¶ü‡¶®‡ßá‡¶∏ ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º ‡¶¶‡¶æ‡¶Å‡¶°‡¶º‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ö...</td>\n",
       "      <td>Profane</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40544</th>\n",
       "      <td>861411</td>\n",
       "      <td>‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶∞ ‡¶™‡¶æ‡¶∏‡ßá ‡¶•‡¶æ‡¶ï‡ßÅ‡¶® ‡¶ó‡ßá‡¶Æ ‡¶≠‡¶ø‡ßú‡¶ø‡¶ì ‡¶¨‡¶æ‡¶®‡¶æ‡¶á</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40545</th>\n",
       "      <td>743242</td>\n",
       "      <td>‡¶Æ‡¶∞‡¶ï‡ßç‡¶ï‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∂‡ßÅ‡¶≠‡¶ï‡¶æ‡¶Æ‡¶®‡¶æ</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40546 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text    label  \\\n",
       "0      147963  ‡¶ß‡¶®‡ßç‡¶Ø‡¶¨‡¶æ‡¶¶ ‡¶¨‡¶∞‡ßç‡¶°‡¶æ‡¶∞ ‡¶ó‡¶æ‡¶∞‡ßç‡¶° ‡¶¶‡ßá‡¶∞‡¶ï‡ßá ‡¶è‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡¶æ‡¶π‡¶æ‡¶∞‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶π...     None   \n",
       "1      214275  ‡¶õ‡ßã‡¶ü‡¶¨‡ßá‡¶≤‡¶æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßá‡¶ï ‡¶ï‡¶∑‡ßç‡¶ü ‡¶ï‡¶∞‡ßá ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶ó‡¶æ‡¶≤‡¶æ‡¶ó‡¶æ‡¶≤‡¶ø ‡¶∂‡¶ø‡¶ñ‡¶õ‡¶ø‡¶≤‡¶æ‡¶Æ...     None   \n",
       "2      849172          ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶è ‡¶®‡¶ø‡¶ú‡ßá‡¶ï‡ßá ‡¶¨‡¶æ‡¶¶‡ßÅ‡¶∞ ‡¶¨‡¶æ‡¶®‡¶æ‡¶á‡ßü‡¶æ ‡¶´‡ßá‡¶≤‡¶õ‡ßá‡¶® ‡¶∞‡ßá  Abusive   \n",
       "3      821985  ‡¶ö‡¶ø‡¶® ‡¶≠‡¶æ‡¶∞‡¶§ ‡¶∞‡¶æ‡¶∂‡¶ø‡ßü‡¶æ ‡¶è‡¶á ‡¶§‡¶ø‡¶® ‡¶¶‡ßá‡¶∂ ‡¶è‡¶ï ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶ï‡ßá ‡¶∂‡¶æ...     None   \n",
       "4      477288  ‡¶è‡¶ü‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶ï‡ßá ‡¶ï‡¶∞‡¶¨‡ßá‡¶Ø‡ßá ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá ‡¶∏‡ßá‡¶á ‡¶§‡ßã ‡¶π‡¶≤‡ßã ‡¶è‡¶á ...  Abusive   \n",
       "...       ...                                                ...      ...   \n",
       "40541  776466                                 ‡¶∏‡¶§‡ßç‡¶Ø ‡¶ï‡¶•‡¶æ ‡¶§‡ßá‡¶§‡ßÅ ‡¶≤‡¶æ‡¶ó‡ßá     None   \n",
       "40542  849227                 ‡¶è‡¶á ‡¶´‡¶ï‡¶ø‡¶®‡¶®‡¶ø ‡¶Æ‡¶æ‡¶ó‡ßÄ‡¶ü‡¶æ ‡¶Ü‡¶∞ ‡¶ï‡¶§ ‡¶®‡¶æ‡¶ü‡¶ï ‡¶¶‡ßá‡¶ñ‡¶æ‡¶¨‡ßá  Abusive   \n",
       "40543  532697  ‡¶¶‡ßá‡¶ñ‡ßã ‡¶Ü‡¶ú‡¶ï‡ßá ‡¶ï‡¶æ‡¶∞ ‡¶´‡¶ø‡¶ü‡¶®‡ßá‡¶∏ ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º ‡¶¶‡¶æ‡¶Å‡¶°‡¶º‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ö...  Profane   \n",
       "40544  861411              ‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø‡¶∞ ‡¶™‡¶æ‡¶∏‡ßá ‡¶•‡¶æ‡¶ï‡ßÅ‡¶® ‡¶ó‡ßá‡¶Æ ‡¶≠‡¶ø‡ßú‡¶ø‡¶ì ‡¶¨‡¶æ‡¶®‡¶æ‡¶á     None   \n",
       "40545  743242                              ‡¶Æ‡¶∞‡¶ï‡ßç‡¶ï‡ßã‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶∂‡ßÅ‡¶≠‡¶ï‡¶æ‡¶Æ‡¶®‡¶æ     None   \n",
       "\n",
       "       toxic  label_id  \n",
       "0          0         0  \n",
       "1          0         0  \n",
       "2          1         5  \n",
       "3          0         0  \n",
       "4          1         5  \n",
       "...      ...       ...  \n",
       "40541      0         0  \n",
       "40542      1         5  \n",
       "40543      1         4  \n",
       "40544      0         0  \n",
       "40545      0         0  \n",
       "\n",
       "[40546 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2id = {\n",
    "    'None': 0,\n",
    "    'Religious Hate': 1,\n",
    "    'Sexism': 2,\n",
    "    'Political Hate': 3,\n",
    "    'Profane': 4,\n",
    "    'Abusive': 5\n",
    "}\n",
    "id2l = {v: k for k, v in l2id.items()}\n",
    "\n",
    "\n",
    "def clean_label(x):\n",
    "    # handle missing or NaN ‚Üí \"None\"\n",
    "    if pd.isna(x) or x == 'None':\n",
    "        return 'None'\n",
    "    # already list-like e.g. ['Abusive']\n",
    "    if isinstance(x, list):\n",
    "        return x[0] if len(x) > 0 else 'None'\n",
    "    # string cases like \"[]\" or \"[Abusive]\" or \"[Political Hate]\"\n",
    "    x = x.strip(\"[]\").strip()\n",
    "    if x == \"\":\n",
    "        return 'None'\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_df(df):\n",
    "    # Ensure labels are proper lists\n",
    "    df[\"label\"] = df[\"label\"].apply(clean_label)\n",
    "    df[\"label\"] = df[\"label\"].fillna(\"None\")\n",
    "    # Now create binary label\n",
    "    df[\"toxic\"] = df[\"label\"].apply(lambda x: 0 if x == \"None\" else 1)\n",
    "    df[\"label_id\"] = df[\"label\"].map(l2id)\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = process_df(train_df)\n",
    "dev_df  = process_df(dev_df)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee769340-e9b6-457e-9a8c-168769ddf29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12764</td>\n",
       "      <td>‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202933</td>\n",
       "      <td>‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165894</td>\n",
       "      <td>‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124999</td>\n",
       "      <td>‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì</td>\n",
       "      <td>Profane</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535301</td>\n",
       "      <td>‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá</td>\n",
       "      <td>Religious Hate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>908819</td>\n",
       "      <td>‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...</td>\n",
       "      <td>Profane</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>597085</td>\n",
       "      <td>‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>901448</td>\n",
       "      <td>‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>617821</td>\n",
       "      <td>‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>316207</td>\n",
       "      <td>‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0       12764                        ‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé   \n",
       "1      202933                             ‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ   \n",
       "2      165894  ‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...   \n",
       "3      124999                ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì   \n",
       "4      535301                          ‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá   \n",
       "...       ...                                                ...   \n",
       "10195  908819  ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...   \n",
       "10196  597085              ‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá   \n",
       "10197  901448  ‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...   \n",
       "10198  617821  ‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...   \n",
       "10199  316207                                    ‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂   \n",
       "\n",
       "                label  toxic  label_id  \n",
       "0             Abusive      1         5  \n",
       "1                None      0         0  \n",
       "2                None      0         0  \n",
       "3             Profane      1         4  \n",
       "4      Religious Hate      1         1  \n",
       "...               ...    ...       ...  \n",
       "10195         Profane      1         4  \n",
       "10196         Abusive      1         5  \n",
       "10197            None      0         0  \n",
       "10198            None      0         0  \n",
       "10199            None      0         0  \n",
       "\n",
       "[10200 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_df\n",
    "\n",
    "df_val = dev_df\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3882bb28-ffa6-439b-8fab-103412640226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Categories: ['Abusive', 'None', 'Political Hate', 'Profane', 'Religious Hate', 'Sexism']\n"
     ]
    }
   ],
   "source": [
    "toxic_df = df_train\n",
    "target_list = sorted(toxic_df['label'].unique().tolist()) # Sort for consistent column order\n",
    "print(f\"Target Categories: {target_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a1d42a2-c1e2-4ab7-abc4-20332614797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>None</th>\n",
       "      <th>Political Hate</th>\n",
       "      <th>Profane</th>\n",
       "      <th>Religious Hate</th>\n",
       "      <th>Sexism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  Abusive   None  \\\n",
       "0                            ‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé     True  False   \n",
       "1                                 ‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ    False   True   \n",
       "2      ‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...    False   True   \n",
       "3                    ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì    False  False   \n",
       "4                              ‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá    False  False   \n",
       "...                                                  ...      ...    ...   \n",
       "10195  ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...    False  False   \n",
       "10196              ‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá     True  False   \n",
       "10197  ‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...    False   True   \n",
       "10198  ‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...    False   True   \n",
       "10199                                    ‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂    False   True   \n",
       "\n",
       "       Political Hate  Profane  Religious Hate  Sexism  \n",
       "0               False    False           False   False  \n",
       "1               False    False           False   False  \n",
       "2               False    False           False   False  \n",
       "3               False     True           False   False  \n",
       "4               False    False            True   False  \n",
       "...               ...      ...             ...     ...  \n",
       "10195           False     True           False   False  \n",
       "10196           False    False           False   False  \n",
       "10197           False    False           False   False  \n",
       "10198           False    False           False   False  \n",
       "10199           False    False           False   False  \n",
       "\n",
       "[10200 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['label'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val = pd.get_dummies(df_val, columns=['label'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "859019c4-8b71-43f6-b308-81452744e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        # Corrected column name from 'title' or 'Text' to 'text'\n",
    "        self.texts = list(df['text']) \n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "val_dataset = CustomDataset(df_val, tokenizer, MAX_LEN, target_list)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c00cbc4-6678-4afc-9761-b917cde53c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2473: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2535/2535 [09:36<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2380, Train Acc: 0.8987\n",
      "Val Loss: 0.2090, Val Acc: 0.9078\n",
      "\n",
      "--- Epoch 2/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0587: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2535/2535 [09:36<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1907, Train Acc: 0.9196\n",
      "Val Loss: 0.2111, Val Acc: 0.9080\n",
      "\n",
      "--- Epoch 3/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.2893: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2535/2535 [09:34<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1550, Train Acc: 0.9372\n",
      "Val Loss: 0.2326, Val Acc: 0.9063\n"
     ]
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, model_name, target_list):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = AutoModel.from_pretrained(model_name, return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(self.bert_model.config.hidden_size, len(target_list))\n",
    "    \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # --- FIX IS HERE ---\n",
    "        # Instead of pooler_output, we take the last hidden state of the [CLS] token\n",
    "        # output.last_hidden_state has shape (batch_size, sequence_length, hidden_size)\n",
    "        # We select the [CLS] token by indexing with [:, 0, :]\n",
    "        cls_output = output.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        output_dropout = self.dropout(cls_output)\n",
    "        final_output = self.linear(output_dropout)\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# Instantiate the model\n",
    "model = BERTClass(MODEL_NAME, target_list)\n",
    "model.to(device)\n",
    "\n",
    "# ==================================\n",
    "# 4. Loss Function and Optimizer\n",
    "# ==================================\n",
    "# For multi-label classification, BCEWithLogitsLoss is the correct choice.\n",
    "# It combines a Sigmoid layer and the BCELoss in one single class.\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ==================================\n",
    "# 5. Training and Evaluation Functions\n",
    "# ==================================\n",
    "# Your train_model and eval_model functions are well-written and can be used as they are.\n",
    "# I've just adjusted the tqdm progress bar description for more clarity.\n",
    "\n",
    "def train_model(training_loader, model, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    loop = tq(training_loader, leave=True)\n",
    "    for batch_idx, data in enumerate(loop):\n",
    "        ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "        mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "        targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy calculation\n",
    "        outputs_sigmoid = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
    "        targets_np = targets.cpu().detach().numpy()\n",
    "        correct_predictions += np.sum(outputs_sigmoid == targets_np)\n",
    "        num_samples += targets_np.size\n",
    "        \n",
    "        loop.set_description(f\"Train - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model, float(correct_predictions) / num_samples, np.mean(losses)\n",
    "\n",
    "\n",
    "def eval_model(validation_loader, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            outputs_sigmoid = torch.sigmoid(outputs).cpu().detach().numpy().round()\n",
    "            targets_np = targets.cpu().detach().numpy()\n",
    "            correct_predictions += np.sum(outputs_sigmoid == targets_np)\n",
    "            num_samples += targets_np.size\n",
    "\n",
    "    return float(correct_predictions) / num_samples, np.mean(losses)\n",
    "\n",
    "\n",
    "# ==================================\n",
    "# 6. Training Loop\n",
    "# ==================================\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    print(f'\\n--- Epoch {epoch}/{EPOCHS} ---')\n",
    "    \n",
    "    model, train_acc, train_loss = train_model(train_data_loader, model, optimizer)\n",
    "    val_acc, val_loss = eval_model(val_data_loader, model)\n",
    "\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), \"all_label_best_model_state.bin\")\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dc4dee7-7eaf-4701-a639-cf5a47bcef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Pipeline on Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert_model): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Evaluating Pipeline on Test Set ---\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"all_label_best_model_state.bin\"))\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "841bbe99-3fbf-43e7-b2bc-3447e8e72bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting on test data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10200/10200 [01:56<00:00, 87.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import  tqdm\n",
    "\n",
    "def predict_toxicity_pipeline(text, tokenizer, model_2, device, max_len, target_list):\n",
    "    # --- Tokenization (no changes here) ---\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text, add_special_tokens=True, max_length=max_len, padding='max_length',\n",
    "        return_token_type_ids=True, truncation=True, return_attention_mask=True, return_tensors='pt'\n",
    "    )\n",
    "    ids = inputs['input_ids'].to(device)\n",
    "    mask = inputs['attention_mask'].to(device)\n",
    "    \n",
    "    # Check if 'token_type_ids' exists in the tokenizer output\n",
    "    token_ids = inputs['token_type_ids'].to(device) if 'token_type_ids' in inputs else None\n",
    "\n",
    "    with torch.no_grad():\n",
    "       \n",
    "        output_2 =  model_2(ids, mask, token_ids)\n",
    "            \n",
    "            # --- üëá KEY CHANGE IS HERE ---\n",
    "            # 1. Find the index of the label with the highest score (logit)\n",
    "            # We use argmax directly on the logits, which is efficient.\n",
    "            # --- AFTER ---\n",
    "        pred_index = torch.argmax(output_2, dim=1).item()\n",
    "            \n",
    "            # 2. Create a one-hot encoded vector\n",
    "            # This creates an array of zeros...\n",
    "        one_hot_prediction = np.zeros(len(target_list), dtype=int)\n",
    "            # ...and sets the predicted index to 1.\n",
    "        one_hot_prediction[pred_index] = 1\n",
    "            \n",
    "        return one_hot_prediction\n",
    "\n",
    "# --- Your evaluation loop (assuming target_list is defined) ---\n",
    "# Example: target_list = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "all_predictions = []\n",
    "# Ensure test_df, tokenizer, model_1, etc. are correctly defined and loaded\n",
    "for text in tq(test_df['text'], desc=\"Predicting on test data\"):\n",
    "    prediction = predict_toxicity_pipeline(text, tokenizer, model, device, MAX_LEN, target_list)\n",
    "    all_predictions.append(prediction)\n",
    "\n",
    "y_pred = np.array(all_predictions)\n",
    "\n",
    "# Now y_pred will be a 2D array where each row has at most one '1'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e730fbf-d481-4f77-bde6-a15d26066e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43f05743-943a-40cc-8b1a-9d9a60fe755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predicted_Label\n",
      "0         Abusive\n",
      "1            None\n",
      "2            None\n",
      "3         Profane\n",
      "4  Religious Hate\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#'Abusive', 'None', 'Political Hate', 'Profane', 'Religious Hate', 'Sexism'\n",
    "#'Abusive', 'Political Hate', 'Profane', 'Religious Hate', 'Sexism']\n",
    "\n",
    "# Your mapping\n",
    "id2l = {\n",
    "    0: 'Abusive',\n",
    "    1: 'None',\n",
    "    2: 'Political Hate',\n",
    "    3: 'Profane',\n",
    "    4:  'Religious Hate',\n",
    "    5: 'Sexism'\n",
    "}\n",
    "\n",
    "# Example y_pred\n",
    "# y_pred = np.array([[0,0,0,0,0],[0,0,0,1,0],[1,0,0,0,0]])\n",
    "\n",
    "def decode_labels(row):\n",
    "    indices = np.where(row == 1)[0]\n",
    "    if len(indices) == 0:\n",
    "        return \"None\"\n",
    "    # If multiple labels, join them with comma\n",
    "    return \", \".join([id2l[i] for i in indices])\n",
    "\n",
    "# Convert predictions into a DataFrame column\n",
    "df = pd.DataFrame()\n",
    "df[\"Predicted_Label\"] = [decode_labels(row) for row in y_pred]\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c4c6efe-b4cb-4c39-b175-9179574eab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12764</td>\n",
       "      <td>‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202933</td>\n",
       "      <td>‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165894</td>\n",
       "      <td>‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124999</td>\n",
       "      <td>‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì</td>\n",
       "      <td>Profane</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535301</td>\n",
       "      <td>‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá</td>\n",
       "      <td>Religious Hate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>908819</td>\n",
       "      <td>‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...</td>\n",
       "      <td>Profane</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>597085</td>\n",
       "      <td>‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>901448</td>\n",
       "      <td>‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>617821</td>\n",
       "      <td>‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>316207</td>\n",
       "      <td>‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0       12764                        ‡¶á‡¶ú‡¶∞‡¶æ‡¶Ø‡¶º‡ßá‡¶≤‡ßá‡¶∞ ‡¶¨‡¶ø‡¶ö‡¶æ‡¶∞ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡ßé   \n",
       "1      202933                             ‡¶∂‡¶æ‡¶Æ‡ßÄ‡¶Æ ‡¶ì‡¶∏‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶® ‡¶π‡¶æ‡¶∏‡¶ø‡¶®‡¶æ   \n",
       "2      165894  ‡¶π‡ßá‡¶® ‡¶ï‡¶æ‡¶™ ‡¶™‡ßÅ‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶∞‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶∞‡¶æ ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶™‡¶≤‡¶ø‡¶∂‡ßá‡¶∞ ‡¶ï‡¶ø ‡¶π‡¶¨...   \n",
       "3      124999                ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π‡ßç ‡¶è‡¶∏‡¶¨ ‡¶ú‡¶æ‡¶®‡ßã‡¶Ø‡¶º‡¶æ‡¶∞‡¶¶‡ßá‡¶∞ ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßá ‡¶¶‡¶æ‡¶ì   \n",
       "4      535301                          ‡¶á‡¶π‡ßÅ‡¶¶‡¶ø‡¶∞ ‡¶¨‡¶æ‡¶ö‡ßç‡¶ö‡¶æ ‡¶á‡¶π‡ßÅ‡¶¶‡ßÄ ‡¶á ‡¶π‡¶¨‡ßá   \n",
       "...       ...                                                ...   \n",
       "10195  908819  ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶ú‡¶ô‡ßç‡¶ó‡¶ø ‡¶®‡¶ø‡¶ö‡ßÅ ‡¶ú‡¶æ‡¶§ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∂‡¶æ‡¶≤‡¶æ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶¶‡ßá‡¶∂ ...   \n",
       "10196  597085              ‡¶è‡¶∞‡ßá ‡¶π‡ßá‡¶§‡¶ø ‡¶π‡¶æ‡¶ó‡¶≤ ‡¶Ö‡¶á ‡¶ó‡ßá‡¶õ‡ßá ‡¶π‡ßá‡¶§‡¶ø‡¶∞‡ßá ‡¶™‡¶æ‡¶¨‡¶®‡¶æ ‡¶®‡ßá   \n",
       "10197  901448  ‡¶è‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶Æ‡¶æ‡¶® ‡¶π‡¶≤‡ßã ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶∞ ‡¶Æ‡ßÄ‡¶∞ ‡¶ú‡¶æ‡¶´‡¶∞ ‡¶ö‡¶æ‡¶á‡¶≤‡ßá‡¶á ‡¶§‡¶æ...   \n",
       "10198  617821  ‡¶∂‡ßÅ‡¶®‡¶ø ‡¶Ø‡ßá ‡¶è‡¶á ‡¶¶‡ßá‡¶∂‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ó‡¶£‡¶§‡¶æ‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶¨‡¶ø‡¶ß‡¶æ‡¶® ‡¶ï...   \n",
       "10199  316207                                    ‡¶ú‡ßü ‡¶π‡ßã‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶¶‡ßá‡¶∂   \n",
       "\n",
       "                label  toxic  label_id        model  \n",
       "0             Abusive      1         5  bangla-bert  \n",
       "1                None      0         0  bangla-bert  \n",
       "2                None      0         0  bangla-bert  \n",
       "3             Profane      1         4  bangla-bert  \n",
       "4      Religious Hate      1         1  bangla-bert  \n",
       "...               ...    ...       ...          ...  \n",
       "10195         Profane      1         4  bangla-bert  \n",
       "10196         Abusive      1         5  bangla-bert  \n",
       "10197         Abusive      0         0  bangla-bert  \n",
       "10198            None      0         0  bangla-bert  \n",
       "10199            None      0         0  bangla-bert  \n",
       "\n",
       "[10200 rows x 6 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label']=df['Predicted_Label']\n",
    "test_df['model']='bangla-bert'\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c60afaa-aa19-4f5d-a2d7-b73ddfb401e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12764</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202933</td>\n",
       "      <td>None</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165894</td>\n",
       "      <td>None</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124999</td>\n",
       "      <td>Profane</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535301</td>\n",
       "      <td>Religious Hate</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>908819</td>\n",
       "      <td>Profane</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>597085</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>901448</td>\n",
       "      <td>Abusive</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>617821</td>\n",
       "      <td>None</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>316207</td>\n",
       "      <td>None</td>\n",
       "      <td>bangla-bert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id           label        model\n",
       "0       12764         Abusive  bangla-bert\n",
       "1      202933            None  bangla-bert\n",
       "2      165894            None  bangla-bert\n",
       "3      124999         Profane  bangla-bert\n",
       "4      535301  Religious Hate  bangla-bert\n",
       "...       ...             ...          ...\n",
       "10195  908819         Profane  bangla-bert\n",
       "10196  597085         Abusive  bangla-bert\n",
       "10197  901448         Abusive  bangla-bert\n",
       "10198  617821            None  bangla-bert\n",
       "10199  316207            None  bangla-bert\n",
       "\n",
       "[10200 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[['id', 'label', 'model']]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "085e9ba6-75ea-44cb-8375-0b69f67e203b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to final_ensemble.tsv\n"
     ]
    }
   ],
   "source": [
    "test_df.to_csv(\"finalllllll_task1.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Saved to final_ensemble.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec92b21-0267-482a-b8c2-11f9cf591d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
