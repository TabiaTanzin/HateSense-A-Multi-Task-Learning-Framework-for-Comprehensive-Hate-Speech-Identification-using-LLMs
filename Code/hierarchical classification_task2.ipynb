{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c1ddf2-a5df-4213-aea7-d8ea2a4895a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_file = 'blp25_hatespeech_subtask_1B_train.tsv'\n",
    "validation_file = 'blp25_hatespeech_subtask_1B_dev.tsv'\n",
    "test_file = 'blp25_hatespeech_subtask_1B_test.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882097f7-cdf8-42e9-b2e5-aa73f3b5b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "# Load train/val/test DataFrames\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\")\n",
    "dev_df = pd.read_csv(validation_file , sep=\"\\t\")\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b50aef-bc27-426d-ba4b-6aa74eb78364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147963</td>\n",
       "      <td>ধন্যবাদ বর্ডার গার্ড দেরকে এভাবে পাহারা দিতে হ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214275</td>\n",
       "      <td>ছোটবেলায় অনেক কষ্ট করে কিছু গালাগালি শিখছিলাম...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849172</td>\n",
       "      <td>অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>821985</td>\n",
       "      <td>চিন ভারত রাশিয়া এই তিন দেশ এক থাকলে বিশ্বকে শা...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477288</td>\n",
       "      <td>এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35517</th>\n",
       "      <td>790325</td>\n",
       "      <td>তইওয়ানের এত ক্ষমতা হয়নি যে এক টুকরো জায়গা নষ্ট...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35518</th>\n",
       "      <td>328377</td>\n",
       "      <td>চুরের ঘরের চুর হালা</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35519</th>\n",
       "      <td>69803</td>\n",
       "      <td>জাহাঙ্গীর বুদ্ধি নেই মাঠে মারা যাবে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35520</th>\n",
       "      <td>419984</td>\n",
       "      <td>একটা ফেইল্ড এস্টেট এও সুষ্ঠু নির্বাচন হয় নেতার...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35521</th>\n",
       "      <td>538747</td>\n",
       "      <td>ছেমরি হলো মাহফুজ রহমান কে ব্যাবহার করে কেরিয়ার...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35522 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0      147963  ধন্যবাদ বর্ডার গার্ড দেরকে এভাবে পাহারা দিতে হ...   \n",
       "1      214275  ছোটবেলায় অনেক কষ্ট করে কিছু গালাগালি শিখছিলাম...   \n",
       "2      849172          অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে   \n",
       "3      821985  চিন ভারত রাশিয়া এই তিন দেশ এক থাকলে বিশ্বকে শা...   \n",
       "4      477288  এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...   \n",
       "...       ...                                                ...   \n",
       "35517  790325  তইওয়ানের এত ক্ষমতা হয়নি যে এক টুকরো জায়গা নষ্ট...   \n",
       "35518  328377                                চুরের ঘরের চুর হালা   \n",
       "35519   69803                জাহাঙ্গীর বুদ্ধি নেই মাঠে মারা যাবে   \n",
       "35520  419984  একটা ফেইল্ড এস্টেট এও সুষ্ঠু নির্বাচন হয় নেতার...   \n",
       "35521  538747  ছেমরি হলো মাহফুজ রহমান কে ব্যাবহার করে কেরিয়ার...   \n",
       "\n",
       "              label  toxic  label_id  \n",
       "0              None   None         0  \n",
       "1              None   None         0  \n",
       "2        Individual  Toxic         4  \n",
       "3              None   None         0  \n",
       "4        Individual  Toxic         4  \n",
       "...             ...    ...       ...  \n",
       "35517          None   None         0  \n",
       "35518          None   None         0  \n",
       "35519    Individual  Toxic         4  \n",
       "35520  Organization  Toxic         2  \n",
       "35521    Individual  Toxic         4  \n",
       "\n",
       "[35522 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2id = {'None': 0, 'Society': 1, 'Organization': 2, 'Community': 3, 'Individual': 4}\n",
    "id2l = {v: k for k, v in l2id.items()}\n",
    "\n",
    "\n",
    "def clean_label(x):\n",
    "    # handle missing or NaN → \"None\"\n",
    "    if pd.isna(x) or x == 'None':\n",
    "        return 'None'\n",
    "    # already list-like e.g. ['Abusive']\n",
    "    if isinstance(x, list):\n",
    "        return x[0] if len(x) > 0 else 'None'\n",
    "    # string cases like \"[]\" or \"[Abusive]\" or \"[Political Hate]\"\n",
    "    x = x.strip(\"[]\").strip()\n",
    "    if x == \"\":\n",
    "        return 'None'\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_df(df):\n",
    "    # Ensure labels are proper lists\n",
    "    df[\"label\"] = df[\"label\"].apply(clean_label)\n",
    "    df[\"label\"] = df[\"label\"].fillna(\"None\")\n",
    "    # Now create binary label\n",
    "    df[\"toxic\"] = df[\"label\"].apply(lambda x: \"None\" if x == \"None\" else \"Toxic\")\n",
    "    df[\"label_id\"] = df[\"label\"].map(l2id)\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = process_df(train_df)\n",
    "dev_df  = process_df(dev_df)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56656f9a-fac6-4785-a6a0-2a67456a77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  toxic\n",
      "0  ধন্যবাদ বর্ডার গার্ড দেরকে এভাবে পাহারা দিতে হ...   None\n",
      "1  ছোটবেলায় অনেক কষ্ট করে কিছু গালাগালি শিখছিলাম...   None\n",
      "2          অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে  Toxic\n",
      "3  চিন ভারত রাশিয়া এই তিন দেশ এক থাকলে বিশ্বকে শা...   None\n",
      "4  এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...  Toxic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the result\n",
    "print(train_df[['text', 'toxic']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f8649a8-6d23-496e-b5a9-a974fed38517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166449</td>\n",
       "      <td>ইন্ডিয়া কি মাছ ধরা বন্ধ রাখছেএক নদীতে দুইনীতি ...</td>\n",
       "      <td>Society</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267692</td>\n",
       "      <td>লক্ষ টাকা ঘুষ দিয়ে অযোগ্য আর দায়িত্বহীন মানস...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184031</td>\n",
       "      <td>ওহা ভবনের দালাল</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>939131</td>\n",
       "      <td>আর কতো শিখবে আমার সোনার ছেলেরা এগুলো কে টাকা দ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210284</td>\n",
       "      <td>কি সাংঘাতিক ভাই রে তুই</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507</th>\n",
       "      <td>350971</td>\n",
       "      <td>পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>539053</td>\n",
       "      <td>এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>200314</td>\n",
       "      <td>এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>788171</td>\n",
       "      <td>আমি কিনে ফেলছি আই ফোন ১৪</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>562864</td>\n",
       "      <td>ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text         label  \\\n",
       "0     166449  ইন্ডিয়া কি মাছ ধরা বন্ধ রাখছেএক নদীতে দুইনীতি ...       Society   \n",
       "1     267692  লক্ষ টাকা ঘুষ দিয়ে অযোগ্য আর দায়িত্বহীন মানস...  Organization   \n",
       "2     184031                                    ওহা ভবনের দালাল          None   \n",
       "3     939131  আর কতো শিখবে আমার সোনার ছেলেরা এগুলো কে টাকা দ...    Individual   \n",
       "4     210284                             কি সাংঘাতিক ভাই রে তুই    Individual   \n",
       "...      ...                                                ...           ...   \n",
       "2507  350971  পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...          None   \n",
       "2508  539053         এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়          None   \n",
       "2509  200314         এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়    Individual   \n",
       "2510  788171                           আমি কিনে ফেলছি আই ফোন ১৪          None   \n",
       "2511  562864  ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...          None   \n",
       "\n",
       "      toxic  label_id  \n",
       "0     Toxic         1  \n",
       "1     Toxic         2  \n",
       "2      None         0  \n",
       "3     Toxic         4  \n",
       "4     Toxic         4  \n",
       "...     ...       ...  \n",
       "2507   None         0  \n",
       "2508   None         0  \n",
       "2509  Toxic         4  \n",
       "2510   None         0  \n",
       "2511   None         0  \n",
       "\n",
       "[2512 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_df\n",
    "\n",
    "df_val = dev_df\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "affe6a57-3c6a-4360-aacd-1d27e2c9b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 36778\n",
      "Validation size: 1256\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # existing train and dev\n",
    "# df_train = train_df.copy()\n",
    "# df_val   = dev_df.copy()\n",
    "\n",
    "# # split dev_df in half\n",
    "# half = len(df_val) // 2\n",
    "# dev_train = df_val.iloc[:half].reset_index(drop=True)\n",
    "# dev_val   = df_val.iloc[half:].reset_index(drop=True)\n",
    "\n",
    "# # add first half of dev to training set\n",
    "# df_train = pd.concat([df_train, dev_train], ignore_index=True)\n",
    "\n",
    "# # final validation set is the second half\n",
    "# df_val = dev_val\n",
    "\n",
    "# print(\"Train size:\", len(df_train))\n",
    "# print(\"Validation size:\", len(df_val))\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# existing train and dev\n",
    "df_train = train_df.copy()\n",
    "df_val   = dev_df.copy()\n",
    "\n",
    "# --- 75/25 split of dev_df ---\n",
    "n   = len(df_val)\n",
    "cut = int(0.5 * n)  # floor to an integer\n",
    "\n",
    "# (optional) shuffle to avoid order bias:\n",
    "# df_val = df_val.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "dev_train = df_val.iloc[:cut].reset_index(drop=True)  # 75%\n",
    "dev_val   = df_val.iloc[cut:].reset_index(drop=True)  # 25%\n",
    "\n",
    "# add 75% of dev to training set\n",
    "df_train = pd.concat([df_train, dev_train], ignore_index=True)\n",
    "\n",
    "# final validation set is the remaining 25%\n",
    "df_val = dev_val\n",
    "\n",
    "print(\"Train size:\", len(df_train))\n",
    "print(\"Validation size:\", len(df_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8acd29c-740b-470b-a823-54efafcfda8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>147963</td>\n",
       "      <td>ধন্যবাদ বর্ডার গার্ড দেরকে এভাবে পাহারা দিতে হ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214275</td>\n",
       "      <td>ছোটবেলায় অনেক কষ্ট করে কিছু গালাগালি শিখছিলাম...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849172</td>\n",
       "      <td>অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>821985</td>\n",
       "      <td>চিন ভারত রাশিয়া এই তিন দেশ এক থাকলে বিশ্বকে শা...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477288</td>\n",
       "      <td>এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>25078</td>\n",
       "      <td>জার্মান কুত্তা গুলো ভয় পাইছে দৌড়ঁ শুরু</td>\n",
       "      <td>Community</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36774</th>\n",
       "      <td>540478</td>\n",
       "      <td>শালার বাংগালি তোদের পুটানি বেশীপকিন্নি কোথাকার</td>\n",
       "      <td>Society</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36775</th>\n",
       "      <td>601373</td>\n",
       "      <td>মিথ্যাবাীদ খুনি হাসিনা</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36776</th>\n",
       "      <td>295630</td>\n",
       "      <td>সময় টিভি যে একটা দালাল হাসিনার পাছাটা কুত্তা ...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36777</th>\n",
       "      <td>230974</td>\n",
       "      <td>মীরজাফর কে এইভাবে পতিহত করতে হবে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36778 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0      147963  ধন্যবাদ বর্ডার গার্ড দেরকে এভাবে পাহারা দিতে হ...   \n",
       "1      214275  ছোটবেলায় অনেক কষ্ট করে কিছু গালাগালি শিখছিলাম...   \n",
       "2      849172          অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে   \n",
       "3      821985  চিন ভারত রাশিয়া এই তিন দেশ এক থাকলে বিশ্বকে শা...   \n",
       "4      477288  এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...   \n",
       "...       ...                                                ...   \n",
       "36773   25078             জার্মান কুত্তা গুলো ভয় পাইছে দৌড়ঁ শুরু   \n",
       "36774  540478     শালার বাংগালি তোদের পুটানি বেশীপকিন্নি কোথাকার   \n",
       "36775  601373                             মিথ্যাবাীদ খুনি হাসিনা   \n",
       "36776  295630  সময় টিভি যে একটা দালাল হাসিনার পাছাটা কুত্তা ...   \n",
       "36777  230974                   মীরজাফর কে এইভাবে পতিহত করতে হবে   \n",
       "\n",
       "              label  toxic  label_id  \n",
       "0              None   None         0  \n",
       "1              None   None         0  \n",
       "2        Individual  Toxic         4  \n",
       "3              None   None         0  \n",
       "4        Individual  Toxic         4  \n",
       "...             ...    ...       ...  \n",
       "36773     Community  Toxic         3  \n",
       "36774       Society  Toxic         1  \n",
       "36775    Individual  Toxic         4  \n",
       "36776  Organization  Toxic         2  \n",
       "36777    Individual  Toxic         4  \n",
       "\n",
       "[36778 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25442c3b-3a5b-471f-afed-0daac93380cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Categories: ['None', 'Toxic']\n"
     ]
    }
   ],
   "source": [
    "toxic_df = df_train\n",
    "target_list = sorted(toxic_df['toxic'].unique().tolist()) # Sort for consistent column order\n",
    "print(f\"Target Categories: {target_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f447313-7260-4da0-ba2a-aa24bc0697c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>None</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>মিথ্যা নাটক করে লাভ নেই সাজানো নাটক শুরু হয়ে গেছে</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ঘন্টা বাজাতে দফতরের কাজ টা কি আপনি নেবেন নাকি</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ইতিহাসের দীর্ঘতম বিসিএস শেষে মেধাবীদের সাথে এভ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>সময় টিভি আসলে কি চায় ভারত সিদ্ধান্ত মেনে নিলে ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>আমি কিনে ফেলছি আই ফোন ১৪</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   None  Toxic\n",
       "0     মিথ্যা নাটক করে লাভ নেই সাজানো নাটক শুরু হয়ে গেছে  False   True\n",
       "1         ঘন্টা বাজাতে দফতরের কাজ টা কি আপনি নেবেন নাকি   True  False\n",
       "2     ইতিহাসের দীর্ঘতম বিসিএস শেষে মেধাবীদের সাথে এভ...  False   True\n",
       "3     সময় টিভি আসলে কি চায় ভারত সিদ্ধান্ত মেনে নিলে ...  False   True\n",
       "4                      আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি  False   True\n",
       "...                                                 ...    ...    ...\n",
       "1251  পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...   True  False\n",
       "1252         এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়   True  False\n",
       "1253         এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়  False   True\n",
       "1254                           আমি কিনে ফেলছি আই ফোন ১৪   True  False\n",
       "1255  ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...   True  False\n",
       "\n",
       "[1256 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['toxic'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val = pd.get_dummies(df_val, columns=['toxic'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17fe7065-bf0f-46f6-9800-56c44df61496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as tq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from torch.optim import AdamW  # <-- use this instead\n",
    "\n",
    "\n",
    "MODEL_NAME =\"csebuetnlp/banglabert\"\n",
    "# Use a pipeline as a high-level helper\n",
    "#MODEL_NAME = \"google-bert/bert-base-multilingual-cased\"\n",
    "\n",
    "#MODEL_NAME=\"FacebookAI/xlm-roberta-large\"\n",
    "\n",
    "# You can keep these as they are or tune them\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 16\n",
    "EPOCHS = 7\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f5a343a-fa60-406b-98fd-003586889405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as tq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        # Corrected column name from 'title' or 'Text' to 'text'\n",
    "        self.texts = list(df['text']) \n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "val_dataset = CustomDataset(df_val, tokenizer, MAX_LEN, target_list)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b025f33-4bfe-407e-b823-1a2c6062018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TACT model with 2 labels: ['None', 'Toxic']\n",
      "Device: cuda\n",
      "Total parameters: 110,422,210\n",
      "Trainable parameters: 110,422,210\n",
      "\n",
      "Starting training for 7 epochs...\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [08:51<00:00,  4.33it/s, Loss=0.2850, LR=1.74e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.3608, BCE Orig: 0.4818, BCE Pert: 0.4804, InfoNCE: 0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.61it/s, Val Loss=0.4676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.4584, Exact Match Accuracy: 0.7763\n",
      "Per-label accuracies:\n",
      "  None: 0.7818\n",
      "  Toxic: 0.7866\n",
      "✓ New best model saved! Accuracy: 0.7763\n",
      "\n",
      "Epoch 2/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [08:51<00:00,  4.32it/s, Loss=0.1297, LR=1.49e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.2730, BCE Orig: 0.3835, BCE Pert: 0.3829, InfoNCE: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.61it/s, Val Loss=0.7304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.4795, Exact Match Accuracy: 0.7882\n",
      "Per-label accuracies:\n",
      "  None: 0.7914\n",
      "  Toxic: 0.7930\n",
      "✓ New best model saved! Accuracy: 0.7882\n",
      "\n",
      "Epoch 3/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [08:52<00:00,  4.32it/s, Loss=0.1106, LR=1.23e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.2036, BCE Orig: 0.2861, BCE Pert: 0.2858, InfoNCE: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.58it/s, Val Loss=1.0858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.5742, Exact Match Accuracy: 0.7779\n",
      "Per-label accuracies:\n",
      "  None: 0.7826\n",
      "  Toxic: 0.7834\n",
      "\n",
      "Epoch 4/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [08:52<00:00,  4.32it/s, Loss=0.0259, LR=9.71e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1372, BCE Orig: 0.1919, BCE Pert: 0.1910, InfoNCE: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.59it/s, Val Loss=1.4219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.7491, Exact Match Accuracy: 0.7675\n",
      "Per-label accuracies:\n",
      "  None: 0.7691\n",
      "  Toxic: 0.7715\n",
      "\n",
      "Epoch 5/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [08:51<00:00,  4.32it/s, Loss=0.0117, LR=7.14e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0911, BCE Orig: 0.1262, BCE Pert: 0.1258, InfoNCE: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.57it/s, Val Loss=1.5454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.9933, Exact Match Accuracy: 0.7739\n",
      "Per-label accuracies:\n",
      "  None: 0.7755\n",
      "  Toxic: 0.7747\n",
      "\n",
      "Epoch 6/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [09:16<00:00,  4.13it/s, Loss=0.3823, LR=4.57e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0618, BCE Orig: 0.0850, BCE Pert: 0.0847, InfoNCE: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 11.70it/s, Val Loss=1.4977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 1.0672, Exact Match Accuracy: 0.7739\n",
      "Per-label accuracies:\n",
      "  None: 0.7747\n",
      "  Toxic: 0.7747\n",
      "\n",
      "Epoch 7/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 2299/2299 [09:06<00:00,  4.21it/s, Loss=0.0059, LR=2.00e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0415, BCE Orig: 0.0565, BCE Pert: 0.0561, InfoNCE: 0.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.61it/s, Val Loss=1.6532]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 1.2157, Exact Match Accuracy: 0.7755\n",
      "Per-label accuracies:\n",
      "  None: 0.7755\n",
      "  Toxic: 0.7771\n",
      "\n",
      "Training completed! Best exact match accuracy: 0.7882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "# Your existing configuration\n",
    "MODEL_NAME = \"csebuetnlp/banglabert\"\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 16\n",
    "EPOCHS = 7\n",
    "LEARNING_RATE = 2e-5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TACT specific hyperparameters\n",
    "EPSILON = 0.01  # Perturbation factor\n",
    "LAMBDA = 0.3    # Balance parameter between BCE and InfoNCE\n",
    "TEMPERATURE = 0.07  # Temperature for InfoNCE loss\n",
    "\n",
    "class TACTBanglaBERT(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, hidden_dim=768):\n",
    "        super(TACTBanglaBERT, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Multi-label classification head\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # Non-linear projection layer for contrastive learning\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 4, 128)  # Final projection dimension\n",
    "        )\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, targets=None, apply_tact=True):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation from last hidden state\n",
    "        # BanglaBERT doesn't have pooler_output, so we use the [CLS] token (first token)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # [CLS] token is at index 0\n",
    "        \n",
    "        if apply_tact and targets is not None and self.training:\n",
    "            return self.forward_with_tact(pooled_output, targets)\n",
    "        else:\n",
    "            # Standard forward pass\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "            logits = self.classifier(pooled_output)\n",
    "            \n",
    "            loss = None\n",
    "            if targets is not None:\n",
    "                # Multi-label binary cross entropy\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "                \n",
    "            return {\n",
    "                \"loss\": loss, \n",
    "                \"logits\": logits, \n",
    "                \"hidden_states\": pooled_output\n",
    "            }\n",
    "    \n",
    "    def forward_with_tact(self, original_repr, targets):\n",
    "        \"\"\"\n",
    "        Implements TACT training with token-level adversarial perturbations\n",
    "        \"\"\"\n",
    "        # Enable gradients for token representations\n",
    "        original_repr = original_repr.requires_grad_(True)\n",
    "        \n",
    "        # Initial forward pass to compute gradients\n",
    "        pooled_output = self.dropout(original_repr)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Compute binary cross-entropy loss\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "        \n",
    "        # Compute gradients w.r.t. token representations\n",
    "        grad_outputs = torch.ones_like(bce_loss)\n",
    "        grad = torch.autograd.grad(\n",
    "            outputs=bce_loss,\n",
    "            inputs=original_repr,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        # Calculate adversarial perturbation (Equation 5 from TACT paper)\n",
    "        grad_norm = torch.norm(grad, dim=-1, keepdim=True)\n",
    "        grad_norm = torch.clamp(grad_norm, min=1e-8)  # Avoid division by zero\n",
    "        perturbation = -EPSILON * (grad / grad_norm)\n",
    "        \n",
    "        # Generate perturbed representation (Equation 6)\n",
    "        perturbed_repr = original_repr + perturbation\n",
    "        \n",
    "        # Forward pass with original representation\n",
    "        pooled_original = self.dropout(original_repr)\n",
    "        logits_original = self.classifier(pooled_original)\n",
    "        proj_original = self.projection(pooled_original)\n",
    "        \n",
    "        # Forward pass with perturbed representation  \n",
    "        pooled_perturbed = self.dropout(perturbed_repr)\n",
    "        logits_perturbed = self.classifier(pooled_perturbed)\n",
    "        proj_perturbed = self.projection(pooled_perturbed)\n",
    "        \n",
    "        # Compute losses\n",
    "        bce_loss_original = F.binary_cross_entropy_with_logits(logits_original, targets)\n",
    "        bce_loss_perturbed = F.binary_cross_entropy_with_logits(logits_perturbed, targets)\n",
    "        \n",
    "        # InfoNCE Loss for contrastive learning\n",
    "        infonce_loss = self.compute_infonce_loss(proj_original, proj_perturbed)\n",
    "        \n",
    "        # Combined loss (Equation 7 from TACT paper)\n",
    "        total_loss = (1 - LAMBDA) / 2 * (bce_loss_original + bce_loss_perturbed) + LAMBDA * infonce_loss\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"logits\": logits_original,\n",
    "            \"hidden_states\": pooled_original,\n",
    "            \"bce_loss_original\": bce_loss_original,\n",
    "            \"bce_loss_perturbed\": bce_loss_perturbed,\n",
    "            \"infonce_loss\": infonce_loss\n",
    "        }\n",
    "    \n",
    "    def compute_infonce_loss(self, z1, z2):\n",
    "        \"\"\"\n",
    "        Compute InfoNCE loss for contrastive learning\n",
    "        \"\"\"\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        z1_norm = F.normalize(z1, dim=-1)\n",
    "        z2_norm = F.normalize(z2, dim=-1)\n",
    "        \n",
    "        # Concatenate representations\n",
    "        representations = torch.cat([z1_norm, z2_norm], dim=0)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(representations, representations.T) / TEMPERATURE\n",
    "        \n",
    "        # Create positive pair labels\n",
    "        labels = torch.cat([torch.arange(batch_size, 2*batch_size), \n",
    "                           torch.arange(0, batch_size)]).to(device)\n",
    "        \n",
    "        # Mask diagonal (self-similarity)\n",
    "        mask = torch.eye(2*batch_size, dtype=torch.bool, device=device)\n",
    "        similarity_matrix.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "        # InfoNCE loss\n",
    "        loss = F.cross_entropy(similarity_matrix, labels)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "class TACTTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, optimizer, scheduler=None):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_accuracy = 0.0\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_bce_original = 0\n",
    "        total_bce_perturbed = 0\n",
    "        total_infonce = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        progress_bar = tq(self.train_loader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move data to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with TACT\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                targets=targets,\n",
    "                apply_tact=True\n",
    "            )\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item()\n",
    "            if 'bce_loss_original' in outputs:\n",
    "                total_bce_original += outputs['bce_loss_original'].item()\n",
    "            if 'bce_loss_perturbed' in outputs:\n",
    "                total_bce_perturbed += outputs['bce_loss_perturbed'].item()\n",
    "            if 'infonce_loss' in outputs:\n",
    "                total_infonce += outputs['infonce_loss'].item()\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'LR': f'{self.optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "        \n",
    "        # Calculate averages\n",
    "        metrics = {\n",
    "            'avg_loss': total_loss / num_batches,\n",
    "            'avg_bce_original': total_bce_original / num_batches,\n",
    "            'avg_bce_perturbed': total_bce_perturbed / num_batches,\n",
    "            'avg_infonce': total_infonce / num_batches\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        num_batches = 0\n",
    "        \n",
    "        progress_bar = tq(self.val_loader, desc=\"Validation\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "                targets = batch['targets'].to(device)\n",
    "                \n",
    "                # Forward pass without TACT\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    targets=targets,\n",
    "                    apply_tact=False\n",
    "                )\n",
    "                \n",
    "                loss = outputs['loss']\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Get predictions\n",
    "                logits = outputs['logits']\n",
    "                predictions = torch.sigmoid(logits)\n",
    "                predicted_labels = (predictions > 0.5).float()\n",
    "                \n",
    "                all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                progress_bar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Calculate metrics\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_targets = np.array(all_targets)\n",
    "        \n",
    "        # Exact match accuracy (all labels must match)\n",
    "        exact_match_accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        \n",
    "        # Per-label accuracy\n",
    "        label_accuracies = []\n",
    "        for i in range(all_targets.shape[1]):\n",
    "            label_acc = accuracy_score(all_targets[:, i], all_predictions[:, i])\n",
    "            label_accuracies.append(label_acc)\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        return avg_loss, exact_match_accuracy, label_accuracies\n",
    "\n",
    "def train_tact_model(train_data_loader, val_data_loader, target_list, num_epochs=EPOCHS):\n",
    "    \"\"\"\n",
    "    Train TACT model using your existing data loaders\n",
    "    \"\"\"\n",
    "    print(f\"Training TACT model with {len(target_list)} labels: {target_list}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(), \n",
    "        lr=LEARNING_RATE, \n",
    "        weight_decay=0.01,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    total_steps = len(train_data_loader) * num_epochs\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, \n",
    "        start_factor=1.0, \n",
    "        end_factor=0.1, \n",
    "        total_iters=total_steps\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = TACTTrainer(model, train_data_loader, val_data_loader, optimizer, scheduler)\n",
    "    \n",
    "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = trainer.train_epoch()\n",
    "        print(f\"Training - Loss: {train_metrics['avg_loss']:.4f}, \"\n",
    "              f\"BCE Orig: {train_metrics['avg_bce_original']:.4f}, \"\n",
    "              f\"BCE Pert: {train_metrics['avg_bce_perturbed']:.4f}, \"\n",
    "              f\"InfoNCE: {train_metrics['avg_infonce']:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, exact_accuracy, label_accuracies = trainer.evaluate()\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Exact Match Accuracy: {exact_accuracy:.4f}\")\n",
    "        \n",
    "        # Print per-label accuracies\n",
    "        print(\"Per-label accuracies:\")\n",
    "        for i, (label_name, acc) in enumerate(zip(target_list, label_accuracies)):\n",
    "            print(f\"  {label_name}: {acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if exact_accuracy > best_accuracy:\n",
    "            best_accuracy = exact_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'target_list': target_list\n",
    "            }, 'best_tact_bangla_model.pth')\n",
    "            print(f\"✓ New best model saved! Accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTraining completed! Best exact match accuracy: {best_accuracy:.4f}\")\n",
    "    return model, trainer\n",
    "\n",
    "# Inference function for your trained model\n",
    "def predict_with_tact(model, text, tokenizer, target_list, max_len=MAX_LEN, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained TACT model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            apply_tact=False\n",
    "        )\n",
    "        \n",
    "        # Get probabilities\n",
    "        logits = outputs['logits']\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "        \n",
    "        # Create result dictionary\n",
    "        results = {}\n",
    "        for i, (label, prob) in enumerate(zip(target_list, probabilities)):\n",
    "            results[label] = {\n",
    "                'probability': float(prob),\n",
    "                'predicted': bool(prob > threshold)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage with your existing setup:\n",
    "\"\"\"\n",
    "# Assuming you already have:\n",
    "# - df_train, df_val dataframes\n",
    "# - target_list (e.g., ['Community', 'Individual', 'None', 'Organization', 'Society'])\n",
    "# - train_data_loader, val_data_loader from your CustomDataset\n",
    "\n",
    "# Train the TACT model\n",
    "model, trainer = train_tact_model(train_data_loader, val_data_loader, target_list)\n",
    "\n",
    "# Make predictions\n",
    "sample_text = \"আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি\"\n",
    "predictions = predict_with_tact(model, sample_text, tokenizer, target_list)\n",
    "print(predictions)\n",
    "\n",
    "# Load saved model for inference\n",
    "checkpoint = torch.load('best_tact_bangla_model.pth')\n",
    "model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\"\"\"\n",
    "\n",
    "# Usage with your existing setup:\n",
    "\n",
    "# Assuming you already have:\n",
    "# - df_train, df_val dataframes\n",
    "# - target_list (e.g., ['Community', 'Individual', 'None', 'Organization', 'Society'])\n",
    "# - train_data_loader, val_data_loader from your CustomDataset\n",
    "\n",
    "# Train the TACT model\n",
    "model, trainer = train_tact_model(train_data_loader, val_data_loader, target_list)\n",
    "\n",
    "# Make predictions\n",
    "# sample_text = \"আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি\"\n",
    "# predictions = predict_with_tact(model, sample_text, tokenizer, target_list)\n",
    "# print(predictions)\n",
    "\n",
    "# # Load saved model for inference\n",
    "# checkpoint = torch.load('best_tact_bangla_model.pth')\n",
    "# model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf469b09-0b01-4b6a-be39-cb5d93135346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>toxic</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849172</td>\n",
       "      <td>অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>477288</td>\n",
       "      <td>এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>786609</td>\n",
       "      <td>ইরান পারমাণবিক বোমা বানাবে বানাবে বলতে বলতে বি...</td>\n",
       "      <td>Society</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>124917</td>\n",
       "      <td>মুসলিম বাচ্চাগুলো বাচ্চা পেরে পেরে গোটা পৃথিবী...</td>\n",
       "      <td>Community</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>432369</td>\n",
       "      <td>বাড়ি বাল ফালায়ছে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>25078</td>\n",
       "      <td>জার্মান কুত্তা গুলো ভয় পাইছে দৌড়ঁ শুরু</td>\n",
       "      <td>Community</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36774</th>\n",
       "      <td>540478</td>\n",
       "      <td>শালার বাংগালি তোদের পুটানি বেশীপকিন্নি কোথাকার</td>\n",
       "      <td>Society</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36775</th>\n",
       "      <td>601373</td>\n",
       "      <td>মিথ্যাবাীদ খুনি হাসিনা</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36776</th>\n",
       "      <td>295630</td>\n",
       "      <td>সময় টিভি যে একটা দালাল হাসিনার পাছাটা কুত্তা ...</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36777</th>\n",
       "      <td>230974</td>\n",
       "      <td>মীরজাফর কে এইভাবে পতিহত করতে হবে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14836 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "2      849172          অতিরিক্ত এ নিজেকে বাদুর বানাইয়া ফেলছেন রে   \n",
       "4      477288  এটার বিচার কে করবেযে বিচার করবে সেই তো হলো এই ...   \n",
       "7      786609  ইরান পারমাণবিক বোমা বানাবে বানাবে বলতে বলতে বি...   \n",
       "11     124917  মুসলিম বাচ্চাগুলো বাচ্চা পেরে পেরে গোটা পৃথিবী...   \n",
       "15     432369                                   বাড়ি বাল ফালায়ছে   \n",
       "...       ...                                                ...   \n",
       "36773   25078             জার্মান কুত্তা গুলো ভয় পাইছে দৌড়ঁ শুরু   \n",
       "36774  540478     শালার বাংগালি তোদের পুটানি বেশীপকিন্নি কোথাকার   \n",
       "36775  601373                             মিথ্যাবাীদ খুনি হাসিনা   \n",
       "36776  295630  সময় টিভি যে একটা দালাল হাসিনার পাছাটা কুত্তা ...   \n",
       "36777  230974                   মীরজাফর কে এইভাবে পতিহত করতে হবে   \n",
       "\n",
       "              label  toxic  label_id  \n",
       "2        Individual  Toxic         4  \n",
       "4        Individual  Toxic         4  \n",
       "7           Society  Toxic         1  \n",
       "11        Community  Toxic         3  \n",
       "15       Individual  Toxic         4  \n",
       "...             ...    ...       ...  \n",
       "36773     Community  Toxic         3  \n",
       "36774       Society  Toxic         1  \n",
       "36775    Individual  Toxic         4  \n",
       "36776  Organization  Toxic         2  \n",
       "36777    Individual  Toxic         4  \n",
       "\n",
       "[14836 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train['label']!='None']\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adde5e39-4361-47f5-97ff-7c50eef560e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list1  = target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eee96d9f-9ffa-4283-944d-8f019f4319d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Categories: ['Community', 'Individual', 'Organization', 'Society']\n"
     ]
    }
   ],
   "source": [
    "toxic_df = df_train\n",
    "target_list = sorted(toxic_df['label'].unique().tolist()) # Sort for consistent column order\n",
    "print(f\"Target Categories: {target_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f2ee617-cc3f-4e33-84ff-3edfeb473848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Community</th>\n",
       "      <th>Individual</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Society</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>মিথ্যা নাটক করে লাভ নেই সাজানো নাটক শুরু হয়ে গেছে</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ঘন্টা বাজাতে দফতরের কাজ টা কি আপনি নেবেন নাকি</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ইতিহাসের দীর্ঘতম বিসিএস শেষে মেধাবীদের সাথে এভ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>সময় টিভি আসলে কি চায় ভারত সিদ্ধান্ত মেনে নিলে ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>আমি কিনে ফেলছি আই ফোন ১৪</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  Community  \\\n",
       "0     মিথ্যা নাটক করে লাভ নেই সাজানো নাটক শুরু হয়ে গেছে      False   \n",
       "1         ঘন্টা বাজাতে দফতরের কাজ টা কি আপনি নেবেন নাকি      False   \n",
       "2     ইতিহাসের দীর্ঘতম বিসিএস শেষে মেধাবীদের সাথে এভ...      False   \n",
       "3     সময় টিভি আসলে কি চায় ভারত সিদ্ধান্ত মেনে নিলে ...      False   \n",
       "4                      আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি      False   \n",
       "...                                                 ...        ...   \n",
       "1251  পুরোনো ইতিহাস তুলে ধরার জন্য সময় সংবাদ কে ধন্...      False   \n",
       "1252         এই জন্যই আমাদের মেয়েরা কোরিয়া চলে যেতে চায়      False   \n",
       "1253         এই শালা ইবলিশ এর বস এবলিশ এদের দেখে ভয় পায়      False   \n",
       "1254                           আমি কিনে ফেলছি আই ফোন ১৪      False   \n",
       "1255  ব্যাংক কর্মকর্তা প্রকাশ্যে বলছেন ব্যাংক লোনের ...      False   \n",
       "\n",
       "      Individual  Organization  Society  \n",
       "0           True         False    False  \n",
       "1          False         False    False  \n",
       "2          False          True    False  \n",
       "3          False          True    False  \n",
       "4          False          True    False  \n",
       "...          ...           ...      ...  \n",
       "1251       False         False    False  \n",
       "1252       False         False    False  \n",
       "1253        True         False    False  \n",
       "1254       False         False    False  \n",
       "1255       False         False    False  \n",
       "\n",
       "[1256 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=['label'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val = pd.get_dummies(df_val, columns=['label'], prefix='', prefix_sep='')[['text'] + target_list]\n",
    "\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "666f30ba-b18f-425d-baa7-692fae4b60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm as tq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, target_list):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        # Corrected column name from 'title' or 'Text' to 'text'\n",
    "        self.texts = list(df['text']) \n",
    "        self.targets = self.df[target_list].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'text': text\n",
    "        }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "train_dataset = CustomDataset(df_train, tokenizer, MAX_LEN, target_list)\n",
    "val_dataset = CustomDataset(df_val, tokenizer, MAX_LEN, target_list)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caa05d87-2233-47cd-b6fd-d53b981453b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TACT model with 4 labels: ['Community', 'Individual', 'Organization', 'Society']\n",
      "Device: cuda\n",
      "Total parameters: 110,423,748\n",
      "Trainable parameters: 110,423,748\n",
      "\n",
      "Starting training for 7 epochs...\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:37<00:00,  4.26it/s, Loss=0.2249, LR=1.74e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.3588, BCE Orig: 0.4411, BCE Pert: 0.4412, InfoNCE: 0.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 11.68it/s, Val Loss=0.2532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.3899, Exact Match Accuracy: 0.4164\n",
      "Per-label accuracies:\n",
      "  Community: 0.9005\n",
      "  Individual: 0.6863\n",
      "  Organization: 0.8846\n",
      "  Society: 0.8774\n",
      "✓ New best model saved! Accuracy: 0.4164\n",
      "\n",
      "Epoch 2/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:37<00:00,  4.26it/s, Loss=0.2084, LR=1.49e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.2330, BCE Orig: 0.3167, BCE Pert: 0.3162, InfoNCE: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.59it/s, Val Loss=0.2498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.4159, Exact Match Accuracy: 0.3790\n",
      "Per-label accuracies:\n",
      "  Community: 0.8702\n",
      "  Individual: 0.6943\n",
      "  Organization: 0.8416\n",
      "  Society: 0.8973\n",
      "\n",
      "Epoch 3/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:34<00:00,  4.33it/s, Loss=0.0395, LR=1.23e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1890, BCE Orig: 0.2590, BCE Pert: 0.2584, InfoNCE: 0.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.68it/s, Val Loss=0.2913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.4522, Exact Match Accuracy: 0.3710\n",
      "Per-label accuracies:\n",
      "  Community: 0.8654\n",
      "  Individual: 0.6967\n",
      "  Organization: 0.8424\n",
      "  Society: 0.8790\n",
      "\n",
      "Epoch 4/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:34<00:00,  4.33it/s, Loss=0.2982, LR=9.71e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1499, BCE Orig: 0.2046, BCE Pert: 0.2039, InfoNCE: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s, Val Loss=0.5189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.5135, Exact Match Accuracy: 0.3288\n",
      "Per-label accuracies:\n",
      "  Community: 0.8583\n",
      "  Individual: 0.7094\n",
      "  Organization: 0.7994\n",
      "  Society: 0.8686\n",
      "\n",
      "Epoch 5/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:34<00:00,  4.33it/s, Loss=0.1315, LR=7.14e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.1174, BCE Orig: 0.1586, BCE Pert: 0.1584, InfoNCE: 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s, Val Loss=0.5633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.5690, Exact Match Accuracy: 0.3073\n",
      "Per-label accuracies:\n",
      "  Community: 0.8471\n",
      "  Individual: 0.7014\n",
      "  Organization: 0.8416\n",
      "  Society: 0.7970\n",
      "\n",
      "Epoch 6/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:34<00:00,  4.33it/s, Loss=0.0944, LR=4.57e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0917, BCE Orig: 0.1224, BCE Pert: 0.1220, InfoNCE: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.63it/s, Val Loss=0.5731]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.6128, Exact Match Accuracy: 0.3018\n",
      "Per-label accuracies:\n",
      "  Community: 0.8328\n",
      "  Individual: 0.6887\n",
      "  Organization: 0.8161\n",
      "  Society: 0.8503\n",
      "\n",
      "Epoch 7/7\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 928/928 [03:34<00:00,  4.33it/s, Loss=0.0846, LR=2.00e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - Loss: 0.0746, BCE Orig: 0.0981, BCE Pert: 0.0978, InfoNCE: 0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 79/79 [00:06<00:00, 12.62it/s, Val Loss=0.5873]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation - Loss: 0.6367, Exact Match Accuracy: 0.2922\n",
      "Per-label accuracies:\n",
      "  Community: 0.8384\n",
      "  Individual: 0.7022\n",
      "  Organization: 0.7930\n",
      "  Society: 0.8392\n",
      "\n",
      "Training completed! Best exact match accuracy: 0.4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm as tq\n",
    "\n",
    "# Your existing configuration\n",
    "MODEL_NAME = \"csebuetnlp/banglabert\"\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VAL_BATCH_SIZE = 16\n",
    "EPOCHS = 7\n",
    "LEARNING_RATE = 2e-5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TACT specific hyperparameters\n",
    "EPSILON = 0.01  # Perturbation factor\n",
    "LAMBDA = 0.3    # Balance parameter between BCE and InfoNCE\n",
    "TEMPERATURE = 0.07  # Temperature for InfoNCE loss\n",
    "\n",
    "class TACTBanglaBERT(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, hidden_dim=768):\n",
    "        super(TACTBanglaBERT, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Multi-label classification head\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # Non-linear projection layer for contrastive learning\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 4, 128)  # Final projection dimension\n",
    "        )\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, targets=None, apply_tact=True):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token representation from last hidden state\n",
    "        # BanglaBERT doesn't have pooler_output, so we use the [CLS] token (first token)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_output = last_hidden_state[:, 0, :]  # [CLS] token is at index 0\n",
    "        \n",
    "        if apply_tact and targets is not None and self.training:\n",
    "            return self.forward_with_tact(pooled_output, targets)\n",
    "        else:\n",
    "            # Standard forward pass\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "            logits = self.classifier(pooled_output)\n",
    "            \n",
    "            loss = None\n",
    "            if targets is not None:\n",
    "                # Multi-label binary cross entropy\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "                \n",
    "            return {\n",
    "                \"loss\": loss, \n",
    "                \"logits\": logits, \n",
    "                \"hidden_states\": pooled_output\n",
    "            }\n",
    "    \n",
    "    def forward_with_tact(self, original_repr, targets):\n",
    "        \"\"\"\n",
    "        Implements TACT training with token-level adversarial perturbations\n",
    "        \"\"\"\n",
    "        # Enable gradients for token representations\n",
    "        original_repr = original_repr.requires_grad_(True)\n",
    "        \n",
    "        # Initial forward pass to compute gradients\n",
    "        pooled_output = self.dropout(original_repr)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        # Compute binary cross-entropy loss\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
    "        \n",
    "        # Compute gradients w.r.t. token representations\n",
    "        grad_outputs = torch.ones_like(bce_loss)\n",
    "        grad = torch.autograd.grad(\n",
    "            outputs=bce_loss,\n",
    "            inputs=original_repr,\n",
    "            grad_outputs=grad_outputs,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        # Calculate adversarial perturbation (Equation 5 from TACT paper)\n",
    "        grad_norm = torch.norm(grad, dim=-1, keepdim=True)\n",
    "        grad_norm = torch.clamp(grad_norm, min=1e-8)  # Avoid division by zero\n",
    "        perturbation = -EPSILON * (grad / grad_norm)\n",
    "        \n",
    "        # Generate perturbed representation (Equation 6)\n",
    "        perturbed_repr = original_repr + perturbation\n",
    "        \n",
    "        # Forward pass with original representation\n",
    "        pooled_original = self.dropout(original_repr)\n",
    "        logits_original = self.classifier(pooled_original)\n",
    "        proj_original = self.projection(pooled_original)\n",
    "        \n",
    "        # Forward pass with perturbed representation  \n",
    "        pooled_perturbed = self.dropout(perturbed_repr)\n",
    "        logits_perturbed = self.classifier(pooled_perturbed)\n",
    "        proj_perturbed = self.projection(pooled_perturbed)\n",
    "        \n",
    "        # Compute losses\n",
    "        bce_loss_original = F.binary_cross_entropy_with_logits(logits_original, targets)\n",
    "        bce_loss_perturbed = F.binary_cross_entropy_with_logits(logits_perturbed, targets)\n",
    "        \n",
    "        # InfoNCE Loss for contrastive learning\n",
    "        infonce_loss = self.compute_infonce_loss(proj_original, proj_perturbed)\n",
    "        \n",
    "        # Combined loss (Equation 7 from TACT paper)\n",
    "        total_loss = (1 - LAMBDA) / 2 * (bce_loss_original + bce_loss_perturbed) + LAMBDA * infonce_loss\n",
    "        \n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"logits\": logits_original,\n",
    "            \"hidden_states\": pooled_original,\n",
    "            \"bce_loss_original\": bce_loss_original,\n",
    "            \"bce_loss_perturbed\": bce_loss_perturbed,\n",
    "            \"infonce_loss\": infonce_loss\n",
    "        }\n",
    "    \n",
    "    def compute_infonce_loss(self, z1, z2):\n",
    "        \"\"\"\n",
    "        Compute InfoNCE loss for contrastive learning\n",
    "        \"\"\"\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        z1_norm = F.normalize(z1, dim=-1)\n",
    "        z2_norm = F.normalize(z2, dim=-1)\n",
    "        \n",
    "        # Concatenate representations\n",
    "        representations = torch.cat([z1_norm, z2_norm], dim=0)\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = torch.matmul(representations, representations.T) / TEMPERATURE\n",
    "        \n",
    "        # Create positive pair labels\n",
    "        labels = torch.cat([torch.arange(batch_size, 2*batch_size), \n",
    "                           torch.arange(0, batch_size)]).to(device)\n",
    "        \n",
    "        # Mask diagonal (self-similarity)\n",
    "        mask = torch.eye(2*batch_size, dtype=torch.bool, device=device)\n",
    "        similarity_matrix.masked_fill_(mask, -float('inf'))\n",
    "        \n",
    "        # InfoNCE loss\n",
    "        loss = F.cross_entropy(similarity_matrix, labels)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "class TACTTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, optimizer, scheduler=None):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_accuracy = 0.0\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_bce_original = 0\n",
    "        total_bce_perturbed = 0\n",
    "        total_infonce = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        progress_bar = tq(self.train_loader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move data to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with TACT\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                targets=targets,\n",
    "                apply_tact=True\n",
    "            )\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item()\n",
    "            if 'bce_loss_original' in outputs:\n",
    "                total_bce_original += outputs['bce_loss_original'].item()\n",
    "            if 'bce_loss_perturbed' in outputs:\n",
    "                total_bce_perturbed += outputs['bce_loss_perturbed'].item()\n",
    "            if 'infonce_loss' in outputs:\n",
    "                total_infonce += outputs['infonce_loss'].item()\n",
    "            \n",
    "            num_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'LR': f'{self.optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "        \n",
    "        # Calculate averages\n",
    "        metrics = {\n",
    "            'avg_loss': total_loss / num_batches,\n",
    "            'avg_bce_original': total_bce_original / num_batches,\n",
    "            'avg_bce_perturbed': total_bce_perturbed / num_batches,\n",
    "            'avg_infonce': total_infonce / num_batches\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        \n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        num_batches = 0\n",
    "        \n",
    "        progress_bar = tq(self.val_loader, desc=\"Validation\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in progress_bar:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "                targets = batch['targets'].to(device)\n",
    "                \n",
    "                # Forward pass without TACT\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    targets=targets,\n",
    "                    apply_tact=False\n",
    "                )\n",
    "                \n",
    "                loss = outputs['loss']\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                # Get predictions\n",
    "                logits = outputs['logits']\n",
    "                predictions = torch.sigmoid(logits)\n",
    "                predicted_labels = (predictions > 0.5).float()\n",
    "                \n",
    "                all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                progress_bar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Calculate metrics\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_targets = np.array(all_targets)\n",
    "        \n",
    "        # Exact match accuracy (all labels must match)\n",
    "        exact_match_accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        \n",
    "        # Per-label accuracy\n",
    "        label_accuracies = []\n",
    "        for i in range(all_targets.shape[1]):\n",
    "            label_acc = accuracy_score(all_targets[:, i], all_predictions[:, i])\n",
    "            label_accuracies.append(label_acc)\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        \n",
    "        return avg_loss, exact_match_accuracy, label_accuracies\n",
    "\n",
    "def train_tact_model(train_data_loader, val_data_loader, target_list, num_epochs=EPOCHS):\n",
    "    \"\"\"\n",
    "    Train TACT model using your existing data loaders\n",
    "    \"\"\"\n",
    "    print(f\"Training TACT model with {len(target_list)} labels: {target_list}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "    \n",
    "    # Print model info\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(), \n",
    "        lr=LEARNING_RATE, \n",
    "        weight_decay=0.01,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    total_steps = len(train_data_loader) * num_epochs\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, \n",
    "        start_factor=1.0, \n",
    "        end_factor=0.1, \n",
    "        total_iters=total_steps\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = TACTTrainer(model, train_data_loader, val_data_loader, optimizer, scheduler)\n",
    "    \n",
    "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Training loop\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = trainer.train_epoch()\n",
    "        print(f\"Training - Loss: {train_metrics['avg_loss']:.4f}, \"\n",
    "              f\"BCE Orig: {train_metrics['avg_bce_original']:.4f}, \"\n",
    "              f\"BCE Pert: {train_metrics['avg_bce_perturbed']:.4f}, \"\n",
    "              f\"InfoNCE: {train_metrics['avg_infonce']:.4f}\")\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, exact_accuracy, label_accuracies = trainer.evaluate()\n",
    "        print(f\"Validation - Loss: {val_loss:.4f}, Exact Match Accuracy: {exact_accuracy:.4f}\")\n",
    "        \n",
    "        # Print per-label accuracies\n",
    "        print(\"Per-label accuracies:\")\n",
    "        for i, (label_name, acc) in enumerate(zip(target_list, label_accuracies)):\n",
    "            print(f\"  {label_name}: {acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if exact_accuracy > best_accuracy:\n",
    "            best_accuracy = exact_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'target_list': target_list\n",
    "            }, 'best_tact_bangla_model2.pth')\n",
    "            print(f\"✓ New best model saved! Accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTraining completed! Best exact match accuracy: {best_accuracy:.4f}\")\n",
    "    return model, trainer\n",
    "\n",
    "# Inference function for your trained model\n",
    "def predict_with_tact(model, text, tokenizer, target_list, max_len=MAX_LEN, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained TACT model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize text\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "    token_type_ids = inputs['token_type_ids'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            apply_tact=False\n",
    "        )\n",
    "        \n",
    "        # Get probabilities\n",
    "        logits = outputs['logits']\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
    "        \n",
    "        # Create result dictionary\n",
    "        results = {}\n",
    "        for i, (label, prob) in enumerate(zip(target_list, probabilities)):\n",
    "            results[label] = {\n",
    "                'probability': float(prob),\n",
    "                'predicted': bool(prob > threshold)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage with your existing setup:\n",
    "\"\"\"\n",
    "# Assuming you already have:\n",
    "# - df_train, df_val dataframes\n",
    "# - target_list (e.g., ['Community', 'Individual', 'None', 'Organization', 'Society'])\n",
    "# - train_data_loader, val_data_loader from your CustomDataset\n",
    "\n",
    "# Train the TACT model\n",
    "model, trainer = train_tact_model(train_data_loader, val_data_loader, target_list)\n",
    "\n",
    "# Make predictions\n",
    "sample_text = \"আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি\"\n",
    "predictions = predict_with_tact(model, sample_text, tokenizer, target_list)\n",
    "print(predictions)\n",
    "\n",
    "# Load saved model for inference\n",
    "checkpoint = torch.load('best_tact_bangla_model.pth')\n",
    "model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\"\"\"\n",
    "\n",
    "# Usage with your existing setup:\n",
    "\n",
    "# Assuming you already have:\n",
    "# - df_train, df_val dataframes\n",
    "# - target_list (e.g., ['Community', 'Individual', 'None', 'Organization', 'Society'])\n",
    "# - train_data_loader, val_data_loader from your CustomDataset\n",
    "\n",
    "# Train the TACT model\n",
    "model2, trainer2 = train_tact_model(train_data_loader, val_data_loader, target_list)\n",
    "\n",
    "# Make predictions\n",
    "# sample_text = \"আমেরিকার হচ্ছে শয়তানের দাদর বাড়ি\"\n",
    "# predictions = predict_with_tact(model, sample_text, tokenizer, target_list)\n",
    "# print(predictions)\n",
    "\n",
    "# # Load saved model for inference\n",
    "# checkpoint = torch.load('best_tact_bangla_model.pth')\n",
    "# model = TACTBanglaBERT(MODEL_NAME, len(target_list)).to(device)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79bb0b-d038-4470-89d8-b2958e8ab69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a8f3d89-e56b-4427-9856-2cb44e3fda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# load checkpoint + target list\n",
    "checkpoint1 = torch.load('best_tact_bangla_model.pth', map_location=device)\n",
    "target_list1 = checkpoint1['target_list']\n",
    "num_labels1 = len(target_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bacc7a8c-34c6-41fd-8785-7dd5cf7cb01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb87d6c6-20b4-4c07-bc0f-2241b2fbe611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load checkpoint + target list\n",
    "checkpoint2 = torch.load('best_tact_bangla_model2.pth', map_location=device)\n",
    "target_list2 = checkpoint2['target_list']\n",
    "num_labels2 = len(target_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfab76f8-19fb-4b9c-83cb-c7db7017d517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb982879-70e5-4af6-9585-1a0aad60e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            str(self.texts[idx]),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {k: v.squeeze(0) for k, v in enc.items()}\n",
    "\n",
    "# dataloader\n",
    "test_ds = TestDataset(test_df['text'].tolist(), tokenizer, MAX_LEN)\n",
    "test_loader = DataLoader(test_ds, batch_size=VAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d60e312-ecc1-4c9f-b494-7f40e189d355",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "# model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b5a04f1-6dae-4df2-a557-db0caf978743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Pipeline on Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TACTBanglaBERT(\n",
       "  (bert): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (projection): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=192, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Evaluating Pipeline on Test Set ---\")\n",
    "\n",
    "model = TACTBanglaBERT(MODEL_NAME, num_labels1).to(device)\n",
    "model.load_state_dict(checkpoint1['model_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a87d406-b228-4b76-a665-f191addec4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Pipeline on Test Set ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TACTBanglaBERT(\n",
       "  (bert): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (projection): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=192, out_features=128, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating Pipeline on Test Set ---\")\n",
    "\n",
    "model2 = TACTBanglaBERT(MODEL_NAME, num_labels2).to(device)\n",
    "model2.load_state_dict(checkpoint2['model_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "model2.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65601dd2-b346-48ae-bf52-34dba1cb77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# from sklearn.metrics import classification_report\n",
    "# import numpy as np\n",
    "\n",
    "# # --- 1. Load the fine-tuned models with truncation ---\n",
    "# pipe_1 = pipeline(\n",
    "#     \"text-classification\",\n",
    "#     model=\"./final_model_task2_1\",\n",
    "#     tokenizer=tokenizer,\n",
    "#     device=-1,   # force CPU\n",
    "#     truncation=True,\n",
    "#     max_length=512\n",
    "# )\n",
    "\n",
    "# pipe_2 = pipeline(\n",
    "#     \"text-classification\",\n",
    "#     model=\"./final_model_task2_2\",\n",
    "#     tokenizer=tokenizer,\n",
    "#     device=-1,\n",
    "#     truncation=True,\n",
    "#     max_length=512,\n",
    "#     return_all_scores=True\n",
    "# )\n",
    "\n",
    "# # --- 2. Run the pipeline on the test set ---\n",
    "# predictions = []\n",
    "# for text in test_df['text']:\n",
    "#     # Model 1: Is it toxic?\n",
    "#     result_1 = pipe_1(text, truncation=True, max_length=512)[0]\n",
    "#     print(result_1)\n",
    "#     is_toxic = 1 if result_1['label'] == 'LABEL_1' else 0\n",
    "#     print(is_toxic)\n",
    "    \n",
    "#     pred_labels = [0] * pipe_2.model.config.num_labels  # default: all zero\n",
    "    \n",
    "#     if is_toxic:\n",
    "#         # Model 2: Which toxic class? (highest score = predicted label)\n",
    "#         result_2 = pipe_2(text, truncation=True, max_length=512)[0]\n",
    "#         best_label = max(result_2, key=lambda x: x['score'])\n",
    "#         pred_labels = [1 if r['label'] == best_label['label'] else 0 for r in result_2]\n",
    "    \n",
    "#     predictions.append(pred_labels)\n",
    "\n",
    "# y_pred = np.array(predictions)\n",
    "# print(y_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d92966c0-6be9-48d8-a78e-a8e4af3b5ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Two-Stage Classification\n",
      "Model 1: Toxic vs None\n",
      "Model 2: Targeted Group (Community, Individual, None, Organization, Society)\n",
      "Classification complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def two_stage_classification(model1, model2, test_loader, device, \n",
    "                           model1_labels, model2_labels):\n",
    "    \"\"\"\n",
    "    Simple two-stage classification:\n",
    "    - Always run Model 1 (toxic vs none)\n",
    "    - If Model 1 predicts 'toxic', run Model 2 (targeted group)\n",
    "    - Return exact predictions from both models\n",
    "    \"\"\"\n",
    "    \n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch.get('token_type_ids')\n",
    "            \n",
    "            if token_type_ids is None:\n",
    "                token_type_ids = torch.zeros_like(input_ids, device=device)\n",
    "            else:\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            batch_size = input_ids.size(0)\n",
    "            \n",
    "            # Model 1 predictions\n",
    "            out1 = model1(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                apply_tact=False\n",
    "            )\n",
    "            \n",
    "            logits1 = out1['logits']\n",
    "            probs1 = torch.sigmoid(logits1).cpu().numpy()\n",
    "            \n",
    "            # Get Model 1 predictions\n",
    "            top1_idx_1 = probs1.argmax(axis=1)\n",
    "            model1_pred_labels = [model1_labels[i] for i in top1_idx_1]\n",
    "            model1_pred_probs = probs1.max(axis=1)\n",
    "            \n",
    "            # Process each sample in batch\n",
    "            for i in range(batch_size):\n",
    "                result = {\n",
    "                    'model1_pred_label': model1_pred_labels[i],\n",
    "                    'model1_pred_prob': model1_pred_probs[i]\n",
    "                }\n",
    "                \n",
    "                # Add all Model 1 probabilities\n",
    "                for j, label in enumerate(model1_labels):\n",
    "                    result[f'model1_prob_{label}'] = probs1[i, j]\n",
    "                \n",
    "                # Run Model 2 if Model 1 predicts toxic\n",
    "                if model1_pred_labels[i] != 'none':\n",
    "                    # Single sample for Model 2\n",
    "                    single_input_ids = input_ids[i:i+1]\n",
    "                    single_attention_mask = attention_mask[i:i+1]\n",
    "                    single_token_type_ids = token_type_ids[i:i+1]\n",
    "                    \n",
    "                    out2 = model2(\n",
    "                        input_ids=single_input_ids,\n",
    "                        attention_mask=single_attention_mask,\n",
    "                        token_type_ids=single_token_type_ids,\n",
    "                        apply_tact=False\n",
    "                    )\n",
    "                    \n",
    "                    logits2 = out2['logits']\n",
    "                    probs2 = torch.sigmoid(logits2).cpu().numpy()[0]\n",
    "                    \n",
    "                    # Get Model 2 predictions\n",
    "                    top1_idx_2 = probs2.argmax()\n",
    "                    model2_pred_label = model2_labels[top1_idx_2]\n",
    "                    model2_pred_prob = probs2.max()\n",
    "                    \n",
    "                    result.update({\n",
    "                        'model2_pred_label': model2_pred_label,\n",
    "                        'model2_pred_prob': model2_pred_prob\n",
    "                    })\n",
    "                    \n",
    "                    # Add all Model 2 probabilities\n",
    "                    for j, label in enumerate(model2_labels):\n",
    "                        result[f'model2_prob_{label}'] = probs2[j]\n",
    "                        \n",
    "                else:\n",
    "                    # Model 1 predicted 'none', no Model 2 needed\n",
    "                    result.update({\n",
    "                        'model2_pred_label': None,\n",
    "                        'model2_pred_prob': None\n",
    "                    })\n",
    "                    \n",
    "                    # Set Model 2 probabilities to None\n",
    "                    for label in model2_labels:\n",
    "                        result[f'model2_prob_{label}'] = None\n",
    "                \n",
    "                all_results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Usage example\n",
    "def run_classification():\n",
    "    \"\"\"\n",
    "    Simple usage example\n",
    "    \"\"\"\n",
    "    # Your models and data\n",
    "    # model1 = your_toxic_vs_none_model\n",
    "    # model2 = your_targeted_group_model  \n",
    "    # test_loader = your_test_dataloader\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model1_labels = ['None', 'Toxic']\n",
    "    model2_labels = ['Community', 'Individual', 'Organization', 'Society']\n",
    "    \n",
    "    # Run classification\n",
    "    results_df = two_stage_classification(\n",
    "        model1=model,\n",
    "        model2=model2,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        model1_labels=model1_labels,\n",
    "        model2_labels=model2_labels\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv('predictions.csv', index=False)\n",
    "    \n",
    "    print(\"Classification complete!\")\n",
    "    return results_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Simple Two-Stage Classification\")\n",
    "    print(\"Model 1: Toxic vs None\")\n",
    "    print(\"Model 2: Targeted Group (Community, Individual, None, Organization, Society)\")\n",
    "    results_df= run_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5b748a0-1f1a-4235-8f70-231993486889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_pred_label</th>\n",
       "      <th>model1_pred_prob</th>\n",
       "      <th>model1_prob_None</th>\n",
       "      <th>model1_prob_Toxic</th>\n",
       "      <th>model2_pred_label</th>\n",
       "      <th>model2_pred_prob</th>\n",
       "      <th>model2_prob_Community</th>\n",
       "      <th>model2_prob_Individual</th>\n",
       "      <th>model2_prob_Organization</th>\n",
       "      <th>model2_prob_Society</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.765944</td>\n",
       "      <td>0.223916</td>\n",
       "      <td>0.765944</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>0.212609</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>0.162958</td>\n",
       "      <td>0.698820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.152591</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.041802</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.036397</td>\n",
       "      <td>0.062195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.192385</td>\n",
       "      <td>0.191014</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.273572</td>\n",
       "      <td>0.064612</td>\n",
       "      <td>0.085645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.088213</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.098670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.662861</td>\n",
       "      <td>0.197042</td>\n",
       "      <td>0.232197</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.662861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.045933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>0.297250</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.053623</td>\n",
       "      <td>0.124087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>None</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.147416</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.464831</td>\n",
       "      <td>0.197194</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.191576</td>\n",
       "      <td>0.464831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>None</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.191677</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.671676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model1_pred_label  model1_pred_prob  model1_prob_None  \\\n",
       "0                 Toxic          0.765944          0.223916   \n",
       "1                  None          0.869882          0.869882   \n",
       "2                 Toxic          0.666546          0.326201   \n",
       "3                 Toxic          0.892045          0.098418   \n",
       "4                 Toxic          0.962215          0.041165   \n",
       "...                 ...               ...               ...   \n",
       "10195             Toxic          0.974814          0.021215   \n",
       "10196             Toxic          0.906622          0.083939   \n",
       "10197             Toxic          0.709862          0.297250   \n",
       "10198              None          0.857183          0.857183   \n",
       "10199              None          0.981624          0.981624   \n",
       "\n",
       "       model1_prob_Toxic model2_pred_label  model2_pred_prob  \\\n",
       "0               0.765944           Society          0.698820   \n",
       "1               0.152591        Individual          0.924347   \n",
       "2               0.666546         Community          0.437921   \n",
       "3               0.892045         Community          0.666176   \n",
       "4               0.962215        Individual          0.872669   \n",
       "...                  ...               ...               ...   \n",
       "10195           0.974814           Society          0.662861   \n",
       "10196           0.906622        Individual          0.944971   \n",
       "10197           0.709862        Individual          0.825428   \n",
       "10198           0.147416           Society          0.464831   \n",
       "10199           0.019624           Society          0.671676   \n",
       "\n",
       "       model2_prob_Community  model2_prob_Individual  \\\n",
       "0                   0.212609                0.099830   \n",
       "1                   0.041802                0.924347   \n",
       "2                   0.437921                0.192385   \n",
       "3                   0.666176                0.273572   \n",
       "4                   0.088213                0.872669   \n",
       "...                      ...                     ...   \n",
       "10195               0.197042                0.232197   \n",
       "10196               0.042090                0.944971   \n",
       "10197               0.093775                0.825428   \n",
       "10198               0.197194                0.106125   \n",
       "10199               0.191677                0.061658   \n",
       "\n",
       "       model2_prob_Organization  model2_prob_Society  \n",
       "0                      0.162958             0.698820  \n",
       "1                      0.036397             0.062195  \n",
       "2                      0.191014             0.107692  \n",
       "3                      0.064612             0.085645  \n",
       "4                      0.036446             0.098670  \n",
       "...                         ...                  ...  \n",
       "10195                  0.065961             0.662861  \n",
       "10196                  0.033354             0.045933  \n",
       "10197                  0.053623             0.124087  \n",
       "10198                  0.191576             0.464831  \n",
       "10199                  0.207809             0.671676  \n",
       "\n",
       "[10200 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e1f70-4e17-4b6d-955f-633c603caf91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "116ec401-04c4-47aa-8bb1-daf6f3f8ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# #'Abusive', 'None', 'Political Hate', 'Profane', 'Religious Hate', 'Sexism'\n",
    "# # #'Abusive', 'Political Hate', 'Profane', 'Religious Hate', 'Sexism']\n",
    "# # 'Community', 'Individual', 'None', 'Organization', 'Society'\n",
    "# # ['Community', 'Individual', 'None', 'Organization', 'Society']\n",
    "# # Your mapping\n",
    "# id2l = {\n",
    "#     0: 'Community',\n",
    "#     1: 'Individual',\n",
    "#     2: 'None',\n",
    "#     3: 'Organization',\n",
    "#     4: 'Society'\n",
    "   \n",
    "# }\n",
    "\n",
    "# # Example y_pred\n",
    "# # y_pred = np.array([[0,0,0,0,0],[0,0,0,1,0],[1,0,0,0,0]])\n",
    "\n",
    "# def decode_labels(row):\n",
    "#     indices = np.where(row == 1)[0]\n",
    "#     if len(indices) == 0:\n",
    "#         return \"None\"\n",
    "#     # If multiple labels, join them with comma\n",
    "#     return \", \".join([id2l[i] for i in indices])\n",
    "\n",
    "# # Convert predictions into a DataFrame column\n",
    "# df = pd.DataFrame()\n",
    "# df[\"Predicted_Label\"] = [decode_labels(row) for row in y_pred]\n",
    "\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9eda570e-53c8-48d4-86b4-4d2a93ec1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_pred_label</th>\n",
       "      <th>model1_pred_prob</th>\n",
       "      <th>model1_prob_None</th>\n",
       "      <th>model1_prob_Toxic</th>\n",
       "      <th>model2_pred_label</th>\n",
       "      <th>model2_pred_prob</th>\n",
       "      <th>model2_prob_Community</th>\n",
       "      <th>model2_prob_Individual</th>\n",
       "      <th>model2_prob_Organization</th>\n",
       "      <th>model2_prob_Society</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.765945</td>\n",
       "      <td>0.223916</td>\n",
       "      <td>0.765945</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>0.212609</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>0.162958</td>\n",
       "      <td>0.698820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.152591</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.041802</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.036397</td>\n",
       "      <td>0.062195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.192385</td>\n",
       "      <td>0.191014</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.273572</td>\n",
       "      <td>0.064612</td>\n",
       "      <td>0.085645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.088213</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.098670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.662861</td>\n",
       "      <td>0.197042</td>\n",
       "      <td>0.232197</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.662861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.045933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>Toxic</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>0.297250</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.053623</td>\n",
       "      <td>0.124087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.147416</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.464831</td>\n",
       "      <td>0.197194</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.191576</td>\n",
       "      <td>0.464831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.191677</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.671676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model1_pred_label  model1_pred_prob  model1_prob_None  \\\n",
       "0                 Toxic          0.765945          0.223916   \n",
       "1                   NaN          0.869882          0.869882   \n",
       "2                 Toxic          0.666546          0.326201   \n",
       "3                 Toxic          0.892045          0.098418   \n",
       "4                 Toxic          0.962215          0.041165   \n",
       "...                 ...               ...               ...   \n",
       "10195             Toxic          0.974814          0.021215   \n",
       "10196             Toxic          0.906622          0.083939   \n",
       "10197             Toxic          0.709862          0.297250   \n",
       "10198               NaN          0.857183          0.857183   \n",
       "10199               NaN          0.981624          0.981624   \n",
       "\n",
       "       model1_prob_Toxic model2_pred_label  model2_pred_prob  \\\n",
       "0               0.765945           Society          0.698820   \n",
       "1               0.152591        Individual          0.924347   \n",
       "2               0.666546         Community          0.437921   \n",
       "3               0.892045         Community          0.666176   \n",
       "4               0.962215        Individual          0.872669   \n",
       "...                  ...               ...               ...   \n",
       "10195           0.974814           Society          0.662861   \n",
       "10196           0.906622        Individual          0.944971   \n",
       "10197           0.709862        Individual          0.825428   \n",
       "10198           0.147416           Society          0.464831   \n",
       "10199           0.019624           Society          0.671676   \n",
       "\n",
       "       model2_prob_Community  model2_prob_Individual  \\\n",
       "0                   0.212609                0.099830   \n",
       "1                   0.041802                0.924347   \n",
       "2                   0.437921                0.192385   \n",
       "3                   0.666176                0.273572   \n",
       "4                   0.088213                0.872669   \n",
       "...                      ...                     ...   \n",
       "10195               0.197042                0.232197   \n",
       "10196               0.042090                0.944971   \n",
       "10197               0.093775                0.825428   \n",
       "10198               0.197194                0.106125   \n",
       "10199               0.191677                0.061658   \n",
       "\n",
       "       model2_prob_Organization  model2_prob_Society  \n",
       "0                      0.162958             0.698820  \n",
       "1                      0.036397             0.062195  \n",
       "2                      0.191014             0.107692  \n",
       "3                      0.064612             0.085645  \n",
       "4                      0.036446             0.098670  \n",
       "...                         ...                  ...  \n",
       "10195                  0.065961             0.662861  \n",
       "10196                  0.033354             0.045933  \n",
       "10197                  0.053623             0.124087  \n",
       "10198                  0.191576             0.464831  \n",
       "10199                  0.207809             0.671676  \n",
       "\n",
       "[10200 rows x 10 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df=pd.read_csv('predictions.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "576e957f-6cfe-4cf5-a705-ebfc902bceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df['model1_pred_label'].fillna('').str.casefold().eq('toxic')\n",
    "df.loc[m, 'model1_pred_label'] = df.loc[m, 'model2_pred_label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f95d0a9c-abec-4fb9-9ebb-0c841afe4329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1_pred_label</th>\n",
       "      <th>model1_pred_prob</th>\n",
       "      <th>model1_prob_None</th>\n",
       "      <th>model1_prob_Toxic</th>\n",
       "      <th>model2_pred_label</th>\n",
       "      <th>model2_pred_prob</th>\n",
       "      <th>model2_prob_Community</th>\n",
       "      <th>model2_prob_Individual</th>\n",
       "      <th>model2_prob_Organization</th>\n",
       "      <th>model2_prob_Society</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Society</td>\n",
       "      <td>0.765945</td>\n",
       "      <td>0.223916</td>\n",
       "      <td>0.765945</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>0.212609</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>0.162958</td>\n",
       "      <td>0.698820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.869882</td>\n",
       "      <td>0.152591</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.041802</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.036397</td>\n",
       "      <td>0.062195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>0.326201</td>\n",
       "      <td>0.666546</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.437921</td>\n",
       "      <td>0.192385</td>\n",
       "      <td>0.191014</td>\n",
       "      <td>0.107692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Community</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>0.098418</td>\n",
       "      <td>0.892045</td>\n",
       "      <td>Community</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.666176</td>\n",
       "      <td>0.273572</td>\n",
       "      <td>0.064612</td>\n",
       "      <td>0.085645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Individual</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.962215</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.088213</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.036446</td>\n",
       "      <td>0.098670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>Society</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.974814</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.662861</td>\n",
       "      <td>0.197042</td>\n",
       "      <td>0.232197</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.662861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>Individual</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.906622</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.944971</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.045933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>Individual</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>0.297250</td>\n",
       "      <td>0.709862</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.093775</td>\n",
       "      <td>0.825428</td>\n",
       "      <td>0.053623</td>\n",
       "      <td>0.124087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.857183</td>\n",
       "      <td>0.147416</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.464831</td>\n",
       "      <td>0.197194</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.191576</td>\n",
       "      <td>0.464831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.981624</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>Society</td>\n",
       "      <td>0.671676</td>\n",
       "      <td>0.191677</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>0.207809</td>\n",
       "      <td>0.671676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model1_pred_label  model1_pred_prob  model1_prob_None  \\\n",
       "0               Society          0.765945          0.223916   \n",
       "1                   NaN          0.869882          0.869882   \n",
       "2             Community          0.666546          0.326201   \n",
       "3             Community          0.892045          0.098418   \n",
       "4            Individual          0.962215          0.041165   \n",
       "...                 ...               ...               ...   \n",
       "10195           Society          0.974814          0.021215   \n",
       "10196        Individual          0.906622          0.083939   \n",
       "10197        Individual          0.709862          0.297250   \n",
       "10198               NaN          0.857183          0.857183   \n",
       "10199               NaN          0.981624          0.981624   \n",
       "\n",
       "       model1_prob_Toxic model2_pred_label  model2_pred_prob  \\\n",
       "0               0.765945           Society          0.698820   \n",
       "1               0.152591        Individual          0.924347   \n",
       "2               0.666546         Community          0.437921   \n",
       "3               0.892045         Community          0.666176   \n",
       "4               0.962215        Individual          0.872669   \n",
       "...                  ...               ...               ...   \n",
       "10195           0.974814           Society          0.662861   \n",
       "10196           0.906622        Individual          0.944971   \n",
       "10197           0.709862        Individual          0.825428   \n",
       "10198           0.147416           Society          0.464831   \n",
       "10199           0.019624           Society          0.671676   \n",
       "\n",
       "       model2_prob_Community  model2_prob_Individual  \\\n",
       "0                   0.212609                0.099830   \n",
       "1                   0.041802                0.924347   \n",
       "2                   0.437921                0.192385   \n",
       "3                   0.666176                0.273572   \n",
       "4                   0.088213                0.872669   \n",
       "...                      ...                     ...   \n",
       "10195               0.197042                0.232197   \n",
       "10196               0.042090                0.944971   \n",
       "10197               0.093775                0.825428   \n",
       "10198               0.197194                0.106125   \n",
       "10199               0.191677                0.061658   \n",
       "\n",
       "       model2_prob_Organization  model2_prob_Society  \n",
       "0                      0.162958             0.698820  \n",
       "1                      0.036397             0.062195  \n",
       "2                      0.191014             0.107692  \n",
       "3                      0.064612             0.085645  \n",
       "4                      0.036446             0.098670  \n",
       "...                         ...                  ...  \n",
       "10195                  0.065961             0.662861  \n",
       "10196                  0.033354             0.045933  \n",
       "10197                  0.053623             0.124087  \n",
       "10198                  0.191576             0.464831  \n",
       "10199                  0.207809             0.671676  \n",
       "\n",
       "[10200 rows x 10 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3f8c5-ee7b-4992-864a-963aacc78d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7237c560-cb2b-4726-9a9f-d069de6e7835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Society', nan, 'Community', 'Individual', 'Organization'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label']=df['model1_pred_label']\n",
    "test_df['model']='TACTBanglaBERT-hyerarchical'\n",
    "test_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01ae1c95-97e8-4eec-82ae-e8810dbca8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12764</td>\n",
       "      <td>ইজরায়েলের বিচার হওয়া উচিৎ</td>\n",
       "      <td>Society</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202933</td>\n",
       "      <td>শামীম ওসামা বিন হাসিনা</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165894</td>\n",
       "      <td>হেন কাপ পুলিশের মারে অন্যরা তাহলে পলিশের কি হব...</td>\n",
       "      <td>Community</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124999</td>\n",
       "      <td>আল্লাহ্ এসব জানোয়ারদের শেষ করে দাও</td>\n",
       "      <td>Community</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535301</td>\n",
       "      <td>ইহুদির বাচ্চা ইহুদী ই হবে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>908819</td>\n",
       "      <td>শালা জঙ্গি নিচু জাত বাংলাদেশের শালা নিজের দেশ ...</td>\n",
       "      <td>Society</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>597085</td>\n",
       "      <td>এরে হেতি হাগল অই গেছে হেতিরে পাবনা নে</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>901448</td>\n",
       "      <td>এখান থেকে প্রমান হলো বাংলার মীর জাফর চাইলেই তা...</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>617821</td>\n",
       "      <td>শুনি যে এই দেশের সংবিধান গণতান্ত্রিক সংবিধান ক...</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>316207</td>\n",
       "      <td>জয় হোক বাংলাদেশ</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text       label  \\\n",
       "0       12764                        ইজরায়েলের বিচার হওয়া উচিৎ     Society   \n",
       "1      202933                             শামীম ওসামা বিন হাসিনা        None   \n",
       "2      165894  হেন কাপ পুলিশের মারে অন্যরা তাহলে পলিশের কি হব...   Community   \n",
       "3      124999                আল্লাহ্ এসব জানোয়ারদের শেষ করে দাও   Community   \n",
       "4      535301                          ইহুদির বাচ্চা ইহুদী ই হবে  Individual   \n",
       "...       ...                                                ...         ...   \n",
       "10195  908819  শালা জঙ্গি নিচু জাত বাংলাদেশের শালা নিজের দেশ ...     Society   \n",
       "10196  597085              এরে হেতি হাগল অই গেছে হেতিরে পাবনা নে  Individual   \n",
       "10197  901448  এখান থেকে প্রমান হলো বাংলার মীর জাফর চাইলেই তা...  Individual   \n",
       "10198  617821  শুনি যে এই দেশের সংবিধান গণতান্ত্রিক সংবিধান ক...        None   \n",
       "10199  316207                                    জয় হোক বাংলাদেশ        None   \n",
       "\n",
       "                             model  \n",
       "0      TACTBanglaBERT-hyerarchical  \n",
       "1      TACTBanglaBERT-hyerarchical  \n",
       "2      TACTBanglaBERT-hyerarchical  \n",
       "3      TACTBanglaBERT-hyerarchical  \n",
       "4      TACTBanglaBERT-hyerarchical  \n",
       "...                            ...  \n",
       "10195  TACTBanglaBERT-hyerarchical  \n",
       "10196  TACTBanglaBERT-hyerarchical  \n",
       "10197  TACTBanglaBERT-hyerarchical  \n",
       "10198  TACTBanglaBERT-hyerarchical  \n",
       "10199  TACTBanglaBERT-hyerarchical  \n",
       "\n",
       "[10200 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.replace({np.nan: \"None\"}) \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71935ab6-9e44-4910-bf21-b579e616c319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12764</td>\n",
       "      <td>Society</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202933</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165894</td>\n",
       "      <td>Community</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124999</td>\n",
       "      <td>Community</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>535301</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>908819</td>\n",
       "      <td>Society</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>597085</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>901448</td>\n",
       "      <td>Individual</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>617821</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>316207</td>\n",
       "      <td>None</td>\n",
       "      <td>TACTBanglaBERT-hyerarchical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       label                        model\n",
       "0       12764     Society  TACTBanglaBERT-hyerarchical\n",
       "1      202933        None  TACTBanglaBERT-hyerarchical\n",
       "2      165894   Community  TACTBanglaBERT-hyerarchical\n",
       "3      124999   Community  TACTBanglaBERT-hyerarchical\n",
       "4      535301  Individual  TACTBanglaBERT-hyerarchical\n",
       "...       ...         ...                          ...\n",
       "10195  908819     Society  TACTBanglaBERT-hyerarchical\n",
       "10196  597085  Individual  TACTBanglaBERT-hyerarchical\n",
       "10197  901448  Individual  TACTBanglaBERT-hyerarchical\n",
       "10198  617821        None  TACTBanglaBERT-hyerarchical\n",
       "10199  316207        None  TACTBanglaBERT-hyerarchical\n",
       "\n",
       "[10200 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[['id', 'label', 'model']]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "756f058f-d25f-4a80-87b2-6ba014e4f014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to final_ensemble.tsv\n"
     ]
    }
   ],
   "source": [
    "test_df.to_csv(\"V7_subtask_2A.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Saved to final_ensemble.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09fbae-5e02-4849-b6c6-4bf1261003e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
