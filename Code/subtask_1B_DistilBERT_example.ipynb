{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Noik9q9c7Bhm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [Hate Speech Identification Shared Task](https://multihate.github.io/): Subtask 1B at [BLP Workshop](https://blp-workshop.github.io/) @IJCNLP-AACL 2025\n",
    "\n",
    "This shared task is designed to identify the type of hate, its severity, and the targeted group from social media content. The goal is to develop robust systems that advance research in this area.\n",
    "\n",
    "In this subtask, given a Bangla text collected from YouTube comments, categorize whether the hate towards individuals, organizations, communities, or society."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSxBhCps7oBf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Downloading dataset from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvwQNYHk6kV5",
    "outputId": "447502f1-3fc3-41aa-9963-402bb45c8cfe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1B/blp25_hatespeech_subtask_1B_train.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1B/blp25_hatespeech_subtask_1B_dev.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1B/blp25_hatespeech_subtask_1B_dev_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYZ96DWt-TZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### installing required libraries.\n",
    " - transformers\n",
    " - datasets\n",
    " - evaluate\n",
    " - accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLJh5GGU-xET",
    "outputId": "f6bd00bc-68ed-43a1-ea73-8a5839d7e663",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "# !pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXhVWUJ3A_hx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### importing required libraries and setting up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VIUAU0rRBOmR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP6CdL7NHpxJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bMzfE34iHyGV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_file = 'blp25_hatespeech_subtask_1B_train.tsv'\n",
    "validation_file = 'blp25_hatespeech_subtask_1B_dev.tsv'\n",
    "test_file = 'blp25_hatespeech_subtask_1B_dev_test.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w59H3fOnLUcG"
   },
   "source": [
    "### Disable wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CRQSQF6MLYrB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-_w4YehCgX4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda=True, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-GUUNj0BPbu",
    "outputId": "ffb5cbd8-2121-44d8-95df-b2de094f2bd9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/t/p/tprama/.local/lib/python3.12/site-packages/transformers/training_args.py:1609: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    output_dir=\"./distilBERT_m/\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    local_rank= 1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=None,\n",
    "    no_cuda=True, \n",
    ")\n",
    "\n",
    "max_train_samples = None\n",
    "max_eval_samples=None\n",
    "max_predict_samples=None\n",
    "max_seq_length = 512\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Q4deAnUJ0iI",
    "outputId": "3b211d54-3b97-4a89-dff9-92b751200afd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/22/2025 17:55:24 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: False\n",
      "08/22/2025 17:55:24 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=False,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./distilBERT_m/runs/Aug22_17-55-24_gpunode002.cluster,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=True,\n",
      "num_train_epochs=3,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./distilBERT_m/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./distilBERT_m/,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.NO,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=True,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgkvwlbFHVo5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-De1tz5qHYre",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'csebuetnlp/banglabert'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPqrrDbcKN8n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### setting the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZvKpoxaQKTB6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNrs7AhKdvl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDwaW8AnKcgD",
    "outputId": "190a1a9f-9714-408b-bcd4-f860f836004b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/22/2025 17:55:26 - INFO - __main__ - loading a local file for train\n",
      "08/22/2025 17:55:26 - INFO - __main__ - loading a local file for validation\n",
      "08/22/2025 17:55:26 - INFO - __main__ - loading a local file for test\n"
     ]
    }
   ],
   "source": [
    "l2id = {'None': 0, 'Society': 1, 'Organization': 2, 'Community': 3, 'Individual': 4}\n",
    "train_df = pd.read_csv(train_file, sep='\\t')\n",
    "# print(train_df['label'])\n",
    "train_df['label'] = train_df['label'].map(l2id).fillna(0).astype(int)\n",
    "train_df = Dataset.from_pandas(train_df)\n",
    "validation_df = pd.read_csv(validation_file, sep='\\t')\n",
    "validation_df['label'] = validation_df['label'].map(l2id).fillna(0).astype(int)\n",
    "validation_df = Dataset.from_pandas(validation_df)\n",
    "test_df = pd.read_csv(test_file, sep='\\t')\n",
    "#test_df['label'] = test_df['label'].map(l2id)\n",
    "test_df = Dataset.from_pandas(test_df)\n",
    "\n",
    "data_files = {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n",
    "for key in data_files.keys():\n",
    "    logger.info(f\"loading a local file for {key}\")\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1swECfaTuJl",
    "outputId": "7b5643cd-99e1-4b59-f6c2-66cd4866b240"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJhNu7tPQ2RU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Extracting number of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTl6NNPmOXhO",
    "outputId": "51e6ab13-27bf-4490-edb3-58dd650854eb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "label_list = raw_datasets[\"train\"].unique(\"label\")\n",
    "print(label_list)\n",
    "label_list.sort()  # sort the labels for determine\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1dpoOAPRJnN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Pretrained Configuration, Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2a367cacc8e244eca07204e5a1647327",
      "5fa63b1d202e4f7fa6d497ebcddf6be3",
      "9b936b66609b4a1db265a547415f2d7f",
      "d595a59d9ccf466981ad948f5f921345",
      "999ad3a10635443886f71957f4a950bc",
      "46e0b4c82fa5448f848d164335556aea",
      "5116a2bdd71e42e094dc536db5712c05",
      "3a53f881f9aa4e799c77bd4992ff59de",
      "ce5e81ba6913445eb60dc4917f1778f4",
      "0dee7d5c03304265919beea131d1c5c8",
      "436c7f44b17f43f58fd40cbf95115cb4",
      "9e4c3c5eb7d74cc79b77b022b1452c99",
      "92fd9a52f460421991342a2d3c7e5fbb",
      "0d2e33660a5a46c4b023f6e156f0a211",
      "80fd84e8643c401aac76389917d1cd48",
      "8531465b19634de787938c583b784282",
      "7b8a6f63de864ddda7171a7329ad18c6",
      "12d7a6ad603a40309eef9041ed8f4a04",
      "24e055f5251847179e5f93a5610c1206",
      "9fdd5aac0ff249ac8c4810cb83ea2cc4",
      "84eac023163d46218e73cc8a13de1539",
      "e0dd9275fd734f419791435b7a46cdab",
      "0b3613a4d4e849fc849cc07f4e8582c3",
      "42f6a05689bc46f4813d455d24056011",
      "f6e8fc7eaf694b038b1e122b4ddd4536",
      "d15425caa34a4590a7f3e38857163ee2",
      "ed7be05dcc9949338204d6ab518fb2ad",
      "4303c4ca6bf749a6a91b5a161f688865",
      "f313d24f8a3448b9b628056785e6f209",
      "59416b9fad2b400e9540e2c678e42ba6",
      "3e4b315b19644420b16deed5187f25f4",
      "29086ae0d34a4dc4b414706e23f6661d",
      "2c59206449024fa68de305b3b2c38c0a",
      "3ff5affc09ae451199d50c0829229ede",
      "52eb3aa1d4484b62b8693e5d6f7fb2a5",
      "64bce23820664926a768a675f616d8e1",
      "4a0ce98f22ab470282a28eff42571152",
      "3bacb25d28e546ada9e8303a765d5f61",
      "1bde985270af4b0f80916351eea69289",
      "69a04f85e9334ee2bcfb0c043cd729ef",
      "5309a7d246e242e1bc506a2d81a6a255",
      "716b0ddf017c4c23a316cfa48ae53443",
      "491d9c31d8cb40f5952653475916c0da",
      "5055cad5968d40e8a4dad427d24d9d47",
      "c1fbc4c2734440d088495be489adc462",
      "fd504c5b5e3d49a0a2245fc43d56aaec",
      "dbca9d47b9ad4e9ab9f56c6d5d773bb9",
      "c9b660fc4cb9430d9d9e04caa6bb804f",
      "7cf1fb8ae46b4ccabe304d1475d96820",
      "97ca98508f78498faa5b69edf565841c",
      "b14afe22d6a94311b822d2707246408e",
      "bb848827148e4838a2250c7f5bf3e7fb",
      "1ceb9026519846c0b687390bb57d055c",
      "8d380155d03f445ea75cacfa85967f9f",
      "b76a38633e504a568c82a78c0cd9ec83"
     ]
    },
    "id": "jmAaMuBuRQd2",
    "outputId": "425a11e9-40da-45a8-dc9a-45c0a2d8c8e7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:699] 2025-08-22 17:55:29,868 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-22 17:55:29,929 >> Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:699] 2025-08-22 17:55:29,979 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-22 17:55:29,979 >> Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,003 >> loading file vocab.txt from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,003 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,003 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,003 >> loading file special_tokens_map.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,004 >> loading file tokenizer_config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-22 17:55:30,004 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|configuration_utils.py:699] 2025-08-22 17:55:30,005 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-22 17:55:30,005 >> Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:699] 2025-08-22 17:55:30,032 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-22 17:55:30,033 >> Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3982] 2025-08-22 17:55:31,470 >> loading weights file pytorch_model.bin from cache at /users/t/p/tprama/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
      "[INFO|safetensors_conversion.py:61] 2025-08-22 17:55:31,519 >> Attempting to create safetensors variant\n",
      "[INFO|modeling_utils.py:4960] 2025-08-22 17:55:31,730 >> Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[INFO|safetensors_conversion.py:74] 2025-08-22 17:55:31,731 >> Safetensors PR exists\n",
      "[WARNING|modeling_utils.py:4972] 2025-08-22 17:55:31,731 >> Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=None,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    from_tf=bool(\".ckpt\" in model_name),\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    "    ignore_mismatched_sizes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7PIQVypeTf4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Preprocessing the raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "4693545502524c2e87dc47f20e0f01f5",
      "a6e8ff077fe64ba3a0fc8af70a31c16f",
      "8200c085e0f3419eb30dc15e722222f2",
      "0bbdd47ccce04bb485278c27f8c7ffbf",
      "703ed98e91c9408a8f657346a69b7a45",
      "c91a2696e18344bc9d1bab35f9e19325",
      "4a6f8746d6ed4648a77b0aca904fc3fd",
      "bafdb97957074fd4a0ef98d23c4d2864",
      "bb0bfa18a6b44215aeb3d697a324ba02",
      "458953e5d11d428daef475f18d4ba873",
      "3fc0f5de84794c4aa327f7db01c6914b",
      "a137785622034127b8e069dccb2e59b7",
      "e8f98dadfd954bae91b71801800af131",
      "2415521496c2441ab7fd54231f258b18",
      "e08526ca5720438eb2fe2621617911b0",
      "76b6b511feea4dad99bffa00c44d0f9b",
      "a000ca0158f1401c86cf03c7db65d363",
      "47f90a5d817748018962efdb1acdfb1e",
      "e0277e8bd0f74ef2a1300ab50fef65a8",
      "0866337f1c9549a5b9fd7b9b4dbb738d",
      "51c32e88db0e48f1b5190b10ba13c6af",
      "542e6f476d6b48f388ae6f8987fb4b3d",
      "6b6a04470c13464686bb2047c699a41e",
      "eb4e8622f50d4930a38ba1475092bd13",
      "02f77d7f9bde474bac73372faeaa309a",
      "254b948d3b76467e99f7f704b585eab8",
      "e387e9c79e41459781cc88b2eae4973e",
      "e6b9e5717d694036be683bd66ecebe9e",
      "e18eef4e065a457183d0f01f2a56d789",
      "36faeccf793546e8a4773b8337439352",
      "e9af982254f243ec9ea223bdac13a334",
      "bfa03284f4474a059e1263aab189f88f",
      "ef627e669d9d4f4ca3fa80b73c967eea"
     ]
    },
    "id": "pqO3YWAZelhd",
    "outputId": "adea08f8-f611-4839-a3bd-1c1119b842d2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5b9aac481a41ec94add95e91320531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/35522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a01d22622204f7dbe0d14119b44cd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5bc7c13c4e408084509a92cdb8d4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_label_column_names = [name for name in raw_datasets[\"train\"].column_names if name != \"label\"]\n",
    "sentence1_key= non_label_column_names[1]\n",
    "\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "# Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "label_to_id = None\n",
    "if (model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if sorted(label_name_to_id.keys()) == sorted(label_list):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "            f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"\n",
    "            \"\\nIgnoring the model labels as a result.\",)\n",
    "\n",
    "if label_to_id is not None:\n",
    "    model.config.label2id = label_to_id\n",
    "    model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "if 128 > tokenizer.model_max_length:\n",
    "    logger.warning(\n",
    "        f\"The max_seq_length passed ({128}) is larger than the maximum length for the\"\n",
    "        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\")\n",
    "max_seq_length = min(128, tokenizer.model_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],))\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASxWKiqifb_g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the training data for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QHoDqrBGgD6F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"train\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a train dataset\")\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "if max_train_samples is not None:\n",
    "    max_train_samples_n = min(len(train_dataset), max_train_samples)\n",
    "    train_dataset = train_dataset.select(range(max_train_samples_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqME25nm-hwo",
    "outputId": "bae519b8-502e-49a0-8dfa-1307a4fb4c82",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 35522\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k72vUTSigOzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the development/evaluation data for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MqrW8ospgUYZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"validation\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a validation dataset\")\n",
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "if max_eval_samples is not None:\n",
    "    max_eval_samples_n = min(len(eval_dataset), max_eval_samples)\n",
    "    eval_dataset = eval_dataset.select(range(max_eval_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7sVqp3hgU4i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the test data for predicting the unseen test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "u0dBjIQggcYs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"test\" not in raw_datasets and \"test_matched\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a test dataset\")\n",
    "predict_dataset = raw_datasets[\"test\"]\n",
    "if max_predict_samples is not None:\n",
    "    max_predict_samples_n = min(len(predict_dataset), max_predict_samples)\n",
    "    predict_dataset = predict_dataset.select(range(max_predict_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqbo1xzRge36",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Log a few random samples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIO2bxSVgkLb",
    "outputId": "2435eaec-b822-44ad-b3a6-8e6a8ee63055",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/22/2025 17:55:35 - INFO - __main__ - Sample 7296 of the training set: {'id': 660, 'text': 'à¦¸à¦°à¦•à¦¾à¦°à§‡à¦° à¦¦à¦¾à§Ÿà¦¿à¦¤à§à¦¬à¦ªà§à¦°à¦¾à¦ªà§à¦¤ à¦¸à¦‚à¦¸à§à¦¥à¦¾ à¦¸à¦•à¦² à¦¬à¦¾à¦£à¦¿à¦œà§à¦¯à¦¿à¦• à¦­à¦¬à¦¨ à¦—à§à¦²à§‹à¦•à§‡ à¦¬à¦›à¦°à§‡ à¦…à¦¨à§à¦¤à¦¤ à¦à¦•à¦¬à¦¾à¦° à¦ªà¦°à¦¿à¦¦à¦°à§à¦¶à¦¨ à¦•à¦°à§‡ à¦°à¦¿à¦ªà§‹à¦°à§à¦Ÿ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à¦¬à§‡à¦¨ à¦à¦•à¦Ÿà¦¾ à¦¬à¦¾à¦£à¦¿à¦œà§à¦¯à¦¿à¦• à¦­à¦¬à¦¨à§‡ à¦¨à¦¿à¦°à¦¾à¦ªà¦¤à§à¦¤à¦¾à¦° à¦¸à¦•à¦² à¦¬à§à¦¯à¦¬à¦¸à§à¦¥à¦¾ à¦¥à¦¾à¦•à¦¾ à¦‰à¦šà¦¿à¦¤ à¦•à¦¿à¦¨à§à¦¤à§ à¦à¦‡ à¦¸à¦¬ à¦¸à¦®à§à¦­à¦¬à§‡à¦° à¦¦à§‡à¦¶à§‡ à¦•à¦¿à¦›à§à¦‡ à¦•à¦°à¦¾ à¦¹à§Ÿ à¦¨à¦¾ à¦à¦‡ à¦¦à§‡à¦¶à§‡ à¦®à¦¾à¦¨à§à¦·à§‡à¦° à¦œà§€à¦¬à¦¨à§‡à¦° à¦•à§‹à¦¨ à¦¦à¦¾à¦® à¦¨à§‡à¦‡ à¦¤à¦¾à¦‡ à¦•à§‡à¦‰ à¦•à§‹à¦¨à¦•à¦¿à¦›à§à¦° à¦¤à¦¦à¦¾à¦°à¦•à¦¿à¦°à¦“ à¦¦à¦°à¦•à¦¾à¦° à¦®à¦¨à§‡ à¦•à¦°à§‡ à¦¨à¦¾', 'label': 0, 'input_ids': [2, 1990, 1, 3145, 2058, 9365, 4906, 13484, 3244, 3216, 1845, 9768, 792, 4097, 3711, 2104, 949, 9365, 8932, 6812, 2058, 1718, 1779, 2575, 925, 830, 889, 1810, 764, 1772, 2068, 913, 1, 795, 830, 1772, 1449, 2314, 886, 2263, 1052, 1070, 1206, 886, 11689, 22104, 411, 463, 2119, 996, 792, 795, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/22/2025 17:55:35 - INFO - __main__ - Sample 1639 of the training set: {'id': 463531, 'text': 'à¦•à§‡ à¦•à§‡ à¦Ÿà¦¾ à¦°à§‹à¦œ à¦°à¦¾à¦–à¦¬à§‹ à¦à¦¬à¦‚ à¦ªà¦¾à¦à¦š à¦“à§Ÿà¦¾à¦•à§à¦¤ à¦¨à¦¾à¦®à¦¾à¦œ à¦†à¦¦à¦¾à§Ÿ à¦•à¦°à¦¬', 'label': 0, 'input_ids': [2, 877, 877, 1632, 3643, 15926, 903, 1740, 1, 6800, 1, 2667, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/22/2025 17:55:35 - INFO - __main__ - Sample 18024 of the training set: {'id': 156766, 'text': 'à¦‰à¦¨à¦¾à¦¦à§‡à¦° à¦‰à¦šà§à¦›à§‡à¦¦ à¦•à¦°à¦¾ à¦‰à¦šà¦¿à¦¤ à¦¹à¦¬à§‡à¦¨à¦¾ à¦‰à¦¨à¦¾à¦°à¦¾ à¦†à¦®à¦¾à¦¦à§‡à¦° à¦œà¦¾à¦¤à¦¿ à¦¸à¦¤à§à¦¤à¦¾à¦° à¦…à¦‚à¦¶', 'label': 0, 'input_ids': [2, 21329, 12087, 913, 2575, 7580, 21838, 1029, 4676, 26898, 1550, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n"
     ]
    }
   ],
   "source": [
    "for index in random.sample(range(len(train_dataset)), 3):\n",
    "    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAcn0Pc8gogF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get the metric function `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1f0018d516854e828290c94aaef4113c",
      "db2eef92804040d89feccdf3981e6f1d",
      "9eff91e8c473407ba3140ebe2c204168",
      "35f0d3ef8d8141b8810654f49ce55546",
      "4f92e18fd6694fb7aa060bb7212245b1",
      "f9709aebfc0a4b24a38b8b24b2d0f3f3",
      "46b4a0d75ff94a0f8ecbb7535f35fe51",
      "e81a3a14437c45509709d04d3d84da8f",
      "701f694850e547c58f6a25799a327fdb",
      "1d55e032f67d4d95915ec433c37e884b",
      "b65f654ef0a843eca9dda6e1190a93d3"
     ]
    },
    "id": "aMWMQdaUgvAq",
    "outputId": "2ee1300f-c209-481d-db12-a7d4a14a7ec4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWUyuBHgxbA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predictions and label_ids field and has to return a dictionary string to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-3VqxkqcgxCC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNWK1Hfbg8-o",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_w6lNh-OhJLC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nYlugPRhNbg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i-rwWO7wOpok"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(\"id\")\n",
    "eval_dataset = eval_dataset.remove_columns(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeJco0JOhPHx",
    "outputId": "4982d72b-1bd9-4c30-edba-759f64e32571",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4128216/1049306949.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUxWn9HrhqRM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "B681qnPFhtY0",
    "outputId": "69195940-849c-4903-8b7e-0f7b9cd5aff2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2405] 2025-08-22 17:55:43,666 >> ***** Running training *****\n",
      "[INFO|trainer.py:2406] 2025-08-22 17:55:43,667 >>   Num examples = 35,522\n",
      "[INFO|trainer.py:2407] 2025-08-22 17:55:43,667 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2408] 2025-08-22 17:55:43,667 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:2411] 2025-08-22 17:55:43,668 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2412] 2025-08-22 17:55:43,668 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2413] 2025-08-22 17:55:43,668 >>   Total optimization steps = 6,663\n",
      "[INFO|trainer.py:2414] 2025-08-22 17:55:43,669 >>   Number of trainable parameters = 110,621,189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1989' max='6663' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1989/6663 35:52 < 1:24:23, 0.92 it/s, Epoch 0.90/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.080200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.941600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.840700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = (\n",
    "    max_train_samples if max_train_samples is not None else len(train_dataset)\n",
    ")\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaaRglkwllSp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UwoMEbAloMx",
    "outputId": "1a9141b8-1d25-47b1-ec34-2451efcabcca",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4019] 2025-07-11 07:32:53,096 >> Saving model checkpoint to ./distilBERT_m/\n",
      "[INFO|configuration_utils.py:437] 2025-07-11 07:32:53,099 >> Configuration saved in ./distilBERT_m/config.json\n",
      "[INFO|modeling_utils.py:3949] 2025-07-11 07:33:01,067 >> Model weights saved in ./distilBERT_m/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2507] 2025-07-11 07:33:01,072 >> tokenizer config file saved in ./distilBERT_m/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2516] 2025-07-11 07:33:01,073 >> Special tokens file saved in ./distilBERT_m/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =  1095644GF\n",
      "  train_loss               =     0.9517\n",
      "  train_runtime            = 0:07:31.83\n",
      "  train_samples            =      35522\n",
      "  train_samples_per_second =     78.618\n",
      "  train_steps_per_second   =      4.916\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9zCKBGEhwb7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluating our model on validation/development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "YClw3dXTh17u",
    "outputId": "65b6484e-be86-47a9-e396-31c01e516404",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:*** Evaluate ***\n",
      "[INFO|trainer.py:4353] 2025-07-11 07:33:01,178 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4355] 2025-07-11 07:33:01,178 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4358] 2025-07-11 07:33:01,179 >>   Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =     0.6939\n",
      "  eval_loss               =     0.8355\n",
      "  eval_runtime            = 0:00:08.92\n",
      "  eval_samples            =       2512\n",
      "  eval_samples_per_second =    281.499\n",
      "  eval_steps_per_second   =     17.594\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "max_eval_samples = (\n",
    "    max_eval_samples if max_eval_samples is not None else len(eval_dataset)\n",
    ")\n",
    "metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3LSdUdPh7uG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predecting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "gnXhVq6Yh_oS",
    "outputId": "8ace4ed3-2abe-470d-f2c4-32e1dadeb7fc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:*** Predict ***\n",
      "[INFO|trainer.py:4353] 2025-07-11 07:33:10,551 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4355] 2025-07-11 07:33:10,551 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4358] 2025-07-11 07:33:10,552 >>   Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Predict results *****\n"
     ]
    }
   ],
   "source": [
    "id2l = {v: k for k, v in l2id.items()}\n",
    "logger.info(\"*** Predict ***\")\n",
    "#predict_dataset = predict_dataset.remove_columns(\"label\")\n",
    "ids = predict_dataset['id']\n",
    "predict_dataset = predict_dataset.remove_columns(\"id\")\n",
    "predictions = trainer.predict(predict_dataset, metric_key_prefix=\"predict\").predictions\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "output_predict_file = os.path.join(training_args.output_dir, f\"subtask_1B.tsv\")\n",
    "if trainer.is_world_process_zero():\n",
    "    with open(output_predict_file, \"w\") as writer:\n",
    "        logger.info(f\"***** Predict results *****\")\n",
    "        writer.write(\"id\\tlabel\\tmodel\\n\")\n",
    "        for index, item in enumerate(predictions):\n",
    "            item = label_list[item]\n",
    "            item = id2l[item]\n",
    "            writer.write(f\"{ids[index]}\\t{item}\\t{model_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Gqqk_24__47",
    "outputId": "cc468399-5a17-4965-c4a4-ccf021a67ba0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879187"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQgoTTIoiI0X",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the model into card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1ooJgrViLVj",
    "outputId": "1be4029d-def8-444e-a711-d1e3ac2679c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modelcard.py:450] 2025-07-11 07:33:19,898 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.693869411945343}]}\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"finetuned_from\": model_name, \"tasks\": \"text-classification\"}\n",
    "trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2Uq2f0CQXvu",
    "outputId": "9f8d7d31-e745-4d4d-dbc2-dfd410c4a5dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: distilBERT_m/subtask_1B.tsv (deflated 90%)\n"
     ]
    }
   ],
   "source": [
    "!zip subtask_1B.zip ./distilBERT_m/subtask_1B.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNFwIyDfQ4Sl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
