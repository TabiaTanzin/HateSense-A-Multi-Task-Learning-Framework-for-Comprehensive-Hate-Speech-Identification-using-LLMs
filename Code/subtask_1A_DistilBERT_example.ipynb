{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Noik9q9c7Bhm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [Hate Speech Identification Shared Task](https://multihate.github.io/): Subtask 1A at [BLP Workshop](https://blp-workshop.github.io/) @IJCNLP-AACL 2025\n",
    "\n",
    "This shared task is designed to identify the type of hate, its severity, and the targeted group from social media content. The goal is to develop robust systems that advance research in this area.\n",
    "\n",
    "In this subtask, given a Bangla text collected from YouTube comments, categorize whether it contains abusive, sexism, religious hate, political hate, profane, or none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSxBhCps7oBf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Downloading dataset from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BvwQNYHk6kV5",
    "outputId": "b67b70b4-66ed-45b6-d3ce-f92f1561ec9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-18 00:57:14--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_train.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8002036 (7.6M) [text/plain]\n",
      "Saving to: ‘blp25_hatespeech_subtask_1A_train.tsv’\n",
      "\n",
      "blp25_hatespeech_su 100%[===================>]   7.63M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-08-18 00:57:15 (73.3 MB/s) - ‘blp25_hatespeech_subtask_1A_train.tsv’ saved [8002036/8002036]\n",
      "\n",
      "--2025-08-18 00:57:15--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 585339 (572K) [text/plain]\n",
      "Saving to: ‘blp25_hatespeech_subtask_1A_dev.tsv’\n",
      "\n",
      "blp25_hatespeech_su 100%[===================>] 571.62K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-08-18 00:57:15 (19.1 MB/s) - ‘blp25_hatespeech_subtask_1A_dev.tsv’ saved [585339/585339]\n",
      "\n",
      "--2025-08-18 00:57:15--  https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev_test.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 548258 (535K) [text/plain]\n",
      "Saving to: ‘blp25_hatespeech_subtask_1A_dev_test.tsv’\n",
      "\n",
      "blp25_hatespeech_su 100%[===================>] 535.41K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-08-18 00:57:15 (17.8 MB/s) - ‘blp25_hatespeech_subtask_1A_dev_test.tsv’ saved [548258/548258]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_train.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev.tsv\n",
    "!wget https://raw.githubusercontent.com/AridHasan/blp25_task1/refs/heads/main/data/subtask_1A/blp25_hatespeech_subtask_1A_dev_test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYZ96DWt-TZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### installing required libraries.\n",
    " - transformers\n",
    " - datasets\n",
    " - evaluate\n",
    " - accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLJh5GGU-xET",
    "outputId": "0b7cdf80-809c-40fb-c01e-f13fb26e2ee0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /users/t/p/tprama/.local/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests->transformers) (2024.6.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /users/t/p/tprama/.local/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /users/t/p/tprama/.local/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /users/t/p/tprama/.local/lib/python3.12/site-packages (0.4.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /users/t/p/tprama/.local/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /users/t/p/tprama/.local/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from evaluate) (0.29.1)\n",
      "Requirement already satisfied: packaging in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: filelock in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /users/t/p/tprama/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in /gpfs1/sw/rh9/pkgs/python3.12-anaconda/2024.06-1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "# !pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXhVWUJ3A_hx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### importing required libraries and setting up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VIUAU0rRBOmR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version, send_example_telemetry\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP6CdL7NHpxJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bMzfE34iHyGV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_file = 'blp25_hatespeech_subtask_1A_train.tsv'\n",
    "validation_file = 'blp25_hatespeech_subtask_1A_dev.tsv'\n",
    "test_file = 'blp25_hatespeech_subtask_1A_dev_test.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w59H3fOnLUcG"
   },
   "source": [
    "### Disable wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CRQSQF6MLYrB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-_w4YehCgX4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting up the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-GUUNj0BPbu",
    "outputId": "3d937d6e-b079-4fbc-d34b-9a6fe5731636",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    output_dir=\"./distilBERT_m/\",\n",
    "    overwrite_output_dir=True,\n",
    "    remove_unused_columns=False,\n",
    "    local_rank= 1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "max_train_samples = None\n",
    "max_eval_samples=None\n",
    "max_predict_samples=None\n",
    "max_seq_length = 512\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Q4deAnUJ0iI",
    "outputId": "192f38ba-296a-4026-fe2c-65b88d7d3a8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:06:04 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0 distributed training: True, 16-bits training: False\n",
      "08/18/2025 00:06:04 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=0,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./distilBERT_m/runs/Aug18_00-05-57_node306.cluster,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./distilBERT_m/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./distilBERT_m/,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.NO,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformers.utils.logging.set_verbosity_info()\n",
    "\n",
    "log_level = training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "logger.warning(\n",
    "    f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "    + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {training_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgkvwlbFHVo5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-De1tz5qHYre",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPqrrDbcKN8n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### setting the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZvKpoxaQKTB6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNrs7AhKdvl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDwaW8AnKcgD",
    "outputId": "7709d37d-9226-4257-961c-878a6805ddd9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:06:14 - INFO - __main__ - loading a local file for train\n",
      "08/18/2025 00:06:14 - INFO - __main__ - loading a local file for validation\n",
      "08/18/2025 00:06:14 - INFO - __main__ - loading a local file for test\n"
     ]
    }
   ],
   "source": [
    "l2id = {'None': 0, 'Religious Hate': 1, 'Sexism': 2, 'Political Hate': 3, 'Profane': 4, 'Abusive': 5}\n",
    "train_df = pd.read_csv(train_file, sep='\\t')\n",
    "# print(train_df['label'])\n",
    "train_df['label'] = train_df['label'].map(l2id).fillna(0).astype(int)\n",
    "train_df = Dataset.from_pandas(train_df)\n",
    "validation_df = pd.read_csv(validation_file, sep='\\t')\n",
    "validation_df['label'] = validation_df['label'].map(l2id).fillna(0).astype(int)\n",
    "validation_df = Dataset.from_pandas(validation_df)\n",
    "test_df = pd.read_csv(test_file, sep='\\t')\n",
    "#test_df['label'] = test_df['label'].map(l2id)\n",
    "test_df = Dataset.from_pandas(test_df)\n",
    "\n",
    "data_files = {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n",
    "for key in data_files.keys():\n",
    "    logger.info(f\"loading a local file for {key}\")\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_df, \"validation\": validation_df, \"test\": test_df}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1swECfaTuJl",
    "outputId": "44f72ccb-9e88-4bf8-e6d6-dbbafe33acc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJhNu7tPQ2RU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Extracting number of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTl6NNPmOXhO",
    "outputId": "d8fde20b-5597-4289-e0db-cb17047f6ba5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 4, 1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Labels\n",
    "label_list = raw_datasets[\"train\"].unique(\"label\")\n",
    "print(label_list)\n",
    "label_list.sort()  # sort the labels for determine\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1dpoOAPRJnN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Pretrained Configuration, Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmAaMuBuRQd2",
    "outputId": "e3e81d02-d08a-4fb1-fdbf-610592068373",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a6b80a2c8148909e5c3ae0b71ac8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:699] 2025-08-18 00:06:24,483 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-18 00:06:24,499 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2634a31b007845e88b0ba2465cfaffa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:699] 2025-08-18 00:06:24,595 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-18 00:06:24,595 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66a082d8b7e499e91c35a19e4b2e84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb5ac45984f4711a4fc803c1a13627e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,008 >> loading file vocab.txt from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,008 >> loading file tokenizer.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,008 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,009 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,009 >> loading file tokenizer_config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2050] 2025-08-18 00:06:25,009 >> loading file chat_template.jinja from cache at None\n",
      "[INFO|configuration_utils.py:699] 2025-08-18 00:06:25,010 >> loading configuration file config.json from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/config.json\n",
      "[INFO|configuration_utils.py:771] 2025-08-18 00:06:25,011 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-multilingual-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94aad506a7d547aaa69a905b8b1e9358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3982] 2025-08-18 00:06:31,589 >> loading weights file model.safetensors from cache at /users/t/p/tprama/.cache/huggingface/hub/models--distilbert-base-multilingual-cased/snapshots/45c032ab32cc946ad88a166f7cb282f58c753c2e/model.safetensors\n",
      "[INFO|modeling_utils.py:4960] 2025-08-18 00:06:31,673 >> Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:4972] 2025-08-18 00:06:31,673 >> Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=None,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    cache_dir=None,\n",
    "    use_fast=True,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    from_tf=bool(\".ckpt\" in model_name),\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=None,\n",
    "    ignore_mismatched_sizes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7PIQVypeTf4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Preprocessing the raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9c9e4b5efd4444b198de361e1e60ee98",
      "e8ff088d8aea429c8904ddf5e30b7423",
      "760e1f384c204fdabcb50dc8f7503543",
      "372f7be9f4a24d44a9d023ce1ab9ee10",
      "95d8ef13b0cd42f4bc2d719b815ce2cf",
      "88858792a8da4d819cc60ddb8e36f3f1",
      "4f96df8a32ec4b0f852022e8aff1b362",
      "050a768a36a5493a8bf34ada920c7c85",
      "54587b6751104015be6bd6f889cde658",
      "3f5fd14f5c754741b85280bb9f0b3d09",
      "db47077ed94c4d668b52f0ae10cb99a7",
      "7dbefe9fda5f4ecdb5b760965692a16f",
      "7e164a3ac04041728597e163e8b6baad",
      "cee42ee7383b441f83d96bdbfdeb42a8",
      "279cfb5747d34857866cb9fbea240d09",
      "6aad03f40bf543788b09f26e325e4b07",
      "4751966ad9b7434eb7384cf0acd1c779",
      "89395a91391047c08048cb333189f756",
      "38c98ec8e5da41adbe65aaa48023dc5c",
      "b1a37623e9474a47a8a1cb29a28a8bd9",
      "9b8815d16be24301aecfc2dbf891802b",
      "84b7d5a8cdb84f079effe447622005a5",
      "71e61ba4ad9443b7bcac4499e19b72a9",
      "dabaf6bf211540e2bbdd88f8e8e1ca85",
      "3935bb8e42ec41888a75d47a33354a25",
      "e80e199777024aaab80bf9520915fa4e",
      "7d565f30045543dca48996f9cd228520",
      "2533a698782c46eabe40b270ee278476",
      "e6865221d828480095a6ddd3c645a2e9",
      "03e39ae2f0d54efb9b19a4fadccf2c07",
      "5cd4d8331e1a43dc8481c316aa81222a",
      "3f8459b76cf14992a9148665e8cf5f6f",
      "93d21af9124f459ca29af0291e5f18bb"
     ]
    },
    "id": "pqO3YWAZelhd",
    "outputId": "bf447b90-67d7-4635-d4fc-196606b3fc1d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dbe5011ba54522b18c8fb8aa8ef9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/35522 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c6f367acb0446d93909ce2c15c2385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913271cc7bac43ea87f2720245a8d9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/2512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_label_column_names = [name for name in raw_datasets[\"train\"].column_names if name != \"label\"]\n",
    "sentence1_key= non_label_column_names[1]\n",
    "\n",
    "# Padding strategy\n",
    "padding = \"max_length\"\n",
    "\n",
    "# Some models have set the order of the labels to use, so let's make sure we do use it.\n",
    "label_to_id = None\n",
    "if (model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id):\n",
    "    # Some have all caps in their config, some don't.\n",
    "    label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "    if sorted(label_name_to_id.keys()) == sorted(label_list):\n",
    "        label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "    else:\n",
    "        logger.warning(\n",
    "            \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "            f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels: {sorted(label_list)}.\"\n",
    "            \"\\nIgnoring the model labels as a result.\",)\n",
    "\n",
    "if label_to_id is not None:\n",
    "    model.config.label2id = label_to_id\n",
    "    model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "if 128 > tokenizer.model_max_length:\n",
    "    logger.warning(\n",
    "        f\"The max_seq_length passed ({128}) is larger than the maximum length for the\"\n",
    "        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\")\n",
    "max_seq_length = min(128, tokenizer.model_max_length)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],))\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "raw_datasets = raw_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    load_from_cache_file=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASxWKiqifb_g",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the training data for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QHoDqrBGgD6F",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"train\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a train dataset\")\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "if max_train_samples is not None:\n",
    "    max_train_samples_n = min(len(train_dataset), max_train_samples)\n",
    "    train_dataset = train_dataset.select(range(max_train_samples_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqME25nm-hwo",
    "outputId": "83490003-2e87-472d-d619-3dc1c88a83cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 35522\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k72vUTSigOzZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the development/evaluation data for evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MqrW8ospgUYZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"validation\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a validation dataset\")\n",
    "eval_dataset = raw_datasets[\"validation\"]\n",
    "if max_eval_samples is not None:\n",
    "    max_eval_samples_n = min(len(eval_dataset), max_eval_samples)\n",
    "    eval_dataset = eval_dataset.select(range(max_eval_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7sVqp3hgU4i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Finalize the test data for predicting the unseen test data using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "u0dBjIQggcYs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if \"test\" not in raw_datasets and \"test_matched\" not in raw_datasets:\n",
    "    raise ValueError(\"requires a test dataset\")\n",
    "predict_dataset = raw_datasets[\"test\"]\n",
    "if max_predict_samples is not None:\n",
    "    max_predict_samples_n = min(len(predict_dataset), max_predict_samples)\n",
    "    predict_dataset = predict_dataset.select(range(max_predict_samples_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqbo1xzRge36",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Log a few random samples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wIO2bxSVgkLb",
    "outputId": "1baa6bce-15a4-4cf2-8616-d179a4395e8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:07:06 - INFO - __main__ - Sample 7296 of the training set: {'id': 660, 'text': 'সরকারের দায়িত্বপ্রাপ্ত সংস্থা সকল বাণিজ্যিক ভবন গুলোকে বছরে অন্তত একবার পরিদর্শন করে রিপোর্ট প্রদান করবেন একটা বাণিজ্যিক ভবনে নিরাপত্তার সকল ব্যবস্থা থাকা উচিত কিন্তু এই সব সম্ভবের দেশে কিছুই করা হয় না এই দেশে মানুষের জীবনের কোন দাম নেই তাই কেউ কোনকিছুর তদারকিরও দরকার মনে করে না', 'label': 3, 'input_ids': [101, 62853, 11421, 100, 978, 22756, 102069, 87664, 17660, 20513, 80198, 15215, 15691, 971, 75762, 950, 30277, 16431, 18243, 32465, 11199, 937, 70115, 13542, 28777, 36213, 29740, 12235, 17511, 11128, 111240, 40433, 13334, 974, 12235, 22335, 47719, 33072, 76677, 948, 11128, 49178, 11737, 28777, 36715, 17660, 20513, 80198, 15215, 15691, 971, 75762, 11199, 967, 27268, 96397, 13542, 72659, 11128, 87664, 970, 15215, 106676, 964, 81661, 66449, 17460, 35003, 14112, 100024, 978, 15002, 111240, 61596, 100047, 88324, 11199, 37855, 14998, 14704, 100, 26109, 14112, 88324, 11199, 109216, 955, 13100, 75762, 11421, 41431, 965, 58354, 967, 59712, 52038, 14998, 82937, 89362, 41431, 70295, 53574, 29261, 963, 77960, 70295, 11128, 18262, 965, 11128, 35884, 84851, 13334, 26109, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/18/2025 00:07:06 - INFO - __main__ - Sample 1639 of the training set: {'id': 463531, 'text': 'কে কে টা রোজ রাখবো এবং পাঁচ ওয়াক্ত নামাজ আদায় করব', 'label': 0, 'input_ids': [101, 82937, 82937, 958, 12079, 974, 16431, 24383, 974, 12079, 42651, 19910, 16431, 12051, 968, 12079, 111219, 39427, 100, 35059, 100277, 100, 948, 11128, 19910, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n",
      "08/18/2025 00:07:06 - INFO - __main__ - Sample 18024 of the training set: {'id': 156766, 'text': 'উনাদের উচ্ছেদ করা উচিত হবেনা উনারা আমাদের জাতি সত্তার অংশ', 'label': 0, 'input_ids': [101, 941, 20979, 16755, 66449, 111240, 32294, 17511, 14704, 66449, 17460, 53761, 20979, 941, 71416, 12079, 938, 55631, 16755, 955, 43004, 12235, 978, 13542, 72659, 11128, 47687, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n"
     ]
    }
   ],
   "source": [
    "for index in random.sample(range(len(train_dataset)), 3):\n",
    "    logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAcn0Pc8gogF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get the metric function `accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aMWMQdaUgvAq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0d75abdc44519a92913b091cfe884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foWUyuBHgxbA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Predictions and label_ids field and has to return a dictionary string to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-3VqxkqcgxCC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNWK1Hfbg8-o",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_w6lNh-OhJLC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2nYlugPRhNbg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "i-rwWO7wOpok"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(\"id\")\n",
    "eval_dataset = eval_dataset.remove_columns(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeJco0JOhPHx",
    "outputId": "97bf3501-d6f0-47b2-d075-c666ab52e1d8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2477861/1049306949.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUxWn9HrhqRM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "B681qnPFhtY0",
    "outputId": "6e337556-7e7d-48e3-cc5b-93d7453e14d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2405] 2025-08-18 00:07:32,975 >> ***** Running training *****\n",
      "[INFO|trainer.py:2406] 2025-08-18 00:07:32,976 >>   Num examples = 35,522\n",
      "[INFO|trainer.py:2407] 2025-08-18 00:07:32,976 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2408] 2025-08-18 00:07:32,976 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:2411] 2025-08-18 00:07:32,976 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:2412] 2025-08-18 00:07:32,977 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2413] 2025-08-18 00:07:32,977 >>   Total optimization steps = 2,221\n",
      "[INFO|trainer.py:2414] 2025-08-18 00:07:32,978 >>   Number of trainable parameters = 135,329,286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2221' max='2221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2221/2221 21:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.846300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2657] 2025-08-18 00:29:25,159 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "max_train_samples = (\n",
    "    max_train_samples if max_train_samples is not None else len(train_dataset)\n",
    ")\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaaRglkwllSp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the tokenizer too for easy upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UwoMEbAloMx",
    "outputId": "4dd504fc-c8b3-4229-c111-7f16b1a81487",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3942] 2025-08-18 00:30:01,045 >> Saving model checkpoint to ./distilBERT_m/\n",
      "[INFO|configuration_utils.py:423] 2025-08-18 00:30:01,047 >> Configuration saved in ./distilBERT_m/config.json\n",
      "[INFO|modeling_utils.py:3040] 2025-08-18 00:30:01,207 >> Model weights saved in ./distilBERT_m/model.safetensors\n",
      "[INFO|tokenization_utils_base.py:2500] 2025-08-18 00:30:01,209 >> tokenizer config file saved in ./distilBERT_m/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2509] 2025-08-18 00:30:01,209 >> Special tokens file saved in ./distilBERT_m/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =        1.0\n",
      "  total_flos               =  1095664GF\n",
      "  train_loss               =     0.9131\n",
      "  train_runtime            = 0:21:52.18\n",
      "  train_samples            =      35522\n",
      "  train_samples_per_second =     27.071\n",
      "  train_steps_per_second   =      1.693\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9zCKBGEhwb7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluating our model on validation/development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "YClw3dXTh17u",
    "outputId": "5936e42f-7648-47eb-e91c-68da6afda7a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:30:03 - INFO - __main__ - *** Evaluate ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4258] 2025-08-18 00:30:03,397 >> \n",
      "***** Running Evaluation *****\n",
      "[INFO|trainer.py:4260] 2025-08-18 00:30:03,397 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4263] 2025-08-18 00:30:03,397 >>   Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        1.0\n",
      "  eval_accuracy           =     0.6883\n",
      "  eval_loss               =     0.7891\n",
      "  eval_runtime            = 0:00:26.24\n",
      "  eval_samples            =       2512\n",
      "  eval_samples_per_second =     95.723\n",
      "  eval_steps_per_second   =      5.983\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"*** Evaluate ***\")\n",
    "\n",
    "metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "\n",
    "max_eval_samples = (\n",
    "    max_eval_samples if max_eval_samples is not None else len(eval_dataset)\n",
    ")\n",
    "metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\n",
    "\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3LSdUdPh7uG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predecting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "gnXhVq6Yh_oS",
    "outputId": "b8a5caab-bbc7-4772-bd74-2576761e3abb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:31:54 - INFO - __main__ - *** Predict ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:4258] 2025-08-18 00:31:54,316 >> \n",
      "***** Running Prediction *****\n",
      "[INFO|trainer.py:4260] 2025-08-18 00:31:54,316 >>   Num examples = 2512\n",
      "[INFO|trainer.py:4263] 2025-08-18 00:31:54,317 >>   Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08/18/2025 00:32:19 - INFO - __main__ - ***** Predict results *****\n"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/banglabert\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Gqqk_24__47",
    "outputId": "38f16392-40ab-4277-ff5a-a333055bdcc2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879187"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQgoTTIoiI0X",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the model into card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1ooJgrViLVj",
    "outputId": "153992af-1ef8-4b26-9df4-25f4a0c328a1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modelcard.py:449] 2025-08-18 00:31:05,527 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6882961988449097}]}\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"finetuned_from\": model_name, \"tasks\": \"text-classification\"}\n",
    "trainer.create_model_card(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2Uq2f0CQXvu",
    "outputId": "b1b2d9a3-9675-4e65-ae1f-e16c7c9bfbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: distilBERT_m/subtask_1A.tsv (deflated 90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!zip subtask_1A.zip ./distilBERT_m/subtask_1A.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yNFwIyDfQ4Sl"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1487713426.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    zip subtask_1A.zip ./distilBERT_m/subtask_1A.tsv\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "zip subtask_1A.zip ./distilBERT_m/subtask_1A.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
